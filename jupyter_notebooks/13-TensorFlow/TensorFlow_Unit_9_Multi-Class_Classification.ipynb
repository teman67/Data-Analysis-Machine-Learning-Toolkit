{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow - Unit 09 - Multiclass Classification\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%202%20-%20Unit%20Objective.png\"> Unit Objectives\n",
    "\n",
    "* Fit a deep learning neural network for Multiclass Classification task\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%204%20-%20Import%20Package%20for%20Learning.png\"> Import Package for Learning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\">  Unit 09 - Multiclass Classification\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Workflow\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Challenge%20test.png\n",
    "\">\n",
    " We will follow the typical process used for supervised learning that we are familiar with, but now with a few tweaks:\n",
    "\n",
    "* Split the dataset into train, validation and test set\n",
    "* Create a pipeline to handle data cleaning, feature engineering and feature scaling\n",
    "* Create the neural network\n",
    "* Fit the pipeline to the train set and transform the other sets\n",
    "* Fit the model to the train and validation set\n",
    "* Evaluate the model\n",
    "* Prediction\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Load and split the data\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let's first load the data. We are using the penguins dataset from seaborn. It has records for 3 different species of penguins, collected from 3 islands in the Palmer Archipelago, Antarctica\n",
    "* Here, we are interested in predicting the penguin species based on a penguin characteristic\n",
    "\n",
    "df = sns.load_dataset('penguins')\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  When you want to create a TensorFlow model for multiclass classification, your target variable needs to be encoded as numerical since TensorFlow handles numbers.\n",
    "* As a result, we create a dictionary that maps the target classes to numbers, then replace them with the target variable.\n",
    "* It is better to do that before splitting the data; otherwise, you would have to do that 3 times, one for each target set (y_train, y_val y_test)\n",
    "\n",
    "target_map = {'Adelie':0, 'Chinstrap':1, 'Gentoo':2}\n",
    "df['species'] = df['species'].replace(target_map)\n",
    "df.head()\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.\n",
    "amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> As part of our workflow, we split the data, but now we will split it into train, validation, and test sets. \n",
    "* First, we split into train and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train, y_test = train_test_split(\n",
    "                                    df.drop(['species'],axis=1),\n",
    "                                    df['species'],\n",
    "                                    test_size=0.2,\n",
    "                                    random_state=0\n",
    "                                    )\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Then, from the train set, we split a validation set. We set the validation set as 20% of the train set\n",
    "* Have a look at the print statement, showing the amount of data we have in each set (train, validation and test)\n",
    "\n",
    "X_train, X_val,y_train, y_val = train_test_split(\n",
    "                                    X_train,\n",
    "                                    y_train,\n",
    "                                    test_size=0.2,\n",
    "                                    random_state=0\n",
    "                                    )\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape)\n",
    "print(\"* Validation set:\",  X_val.shape, y_val.shape)\n",
    "print(\"* Test set:\",   X_test.shape, y_test.shape)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  When you want to create a TensorFlow model for a multiclass classification, you will choose the loss function when compiling the model. The \"first go to\" option is `categorical_crossentropy`, we will use that over the course.\n",
    "* The target variable should be one hot encoded when using this loss function.\n",
    "* We are converting each categorical level into new binary columns, and assigning a binary value of 1 or 0. Each binary column is a category level from the variable. The number of binary columns is the same as the number of classes from that target variable.\n",
    "* The binary column is 1 when the original categorical variable represents the associated binary column. Let's see the example and learn from that. \n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> First, let's inspect the first 5 rows from y_train\n",
    "\n",
    "y_train[:5,]\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We first, get the unique values from the target variables, we will use them here and when creating the model\n",
    "\n",
    "* We use `to_categorical()` function to one hot encode in the format we require. We parse the data to to_categorical() and assign the number of classes.\n",
    "* Let's again inspect the first 5 items from y_train. Note we had 3 classes (0, 1 and 2)\n",
    "* 3 binary columns were created, each representing one of the possible classes (0, 1 or 2). The first row was 1, and when hot encoded, the second binary variable (that represents class 1) has the value 1, where the other binary variables are zero.\n",
    "\n",
    "import os;\n",
    "import tensorflow as tf;\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2';\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "n_labels = y_train.nunique()\n",
    "\n",
    "y_train = to_categorical(y=y_train, num_classes=n_labels)\n",
    "y_val = to_categorical(y=y_val, num_classes=n_labels)\n",
    "y_test = to_categorical(y=y_test, num_classes=n_labels)\n",
    "\n",
    "y_train[:5,]\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Pipeline for data processing\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  We first create a pipeline for preprocessing the data. We will list here the steps, but in a real project, you would have used your knowledge to explore the data and look for data cleaning and feature engineering steps. In this case, the steps are: \n",
    "* Impute missing data with the median for all variables (when you don't parse the `variables` argument, you define all numerical variables to be imputed. This trick saves you time)\n",
    "* Impute the most frequent level in the categorical variables. We again didn't parse the `variables` argument, so it includes all categorical variables, so you didn't have to parse ['island', 'sex']\n",
    "  * Note: you shouldn't do this for all datasets. We had studied the dataset before and concluded we could use this imputer for island and sex, which happen to be categorical variables.\n",
    "* Encode all categorical variables (we have the same rationale from the previous bullet on not parsing explicitly the `variables` argument) \n",
    "* Feature scaling\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "### Feature Engineering\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "from feature_engine.imputation import CategoricalImputer\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "### Feat Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def pipeline_pre_processing():\n",
    "  pipeline_base = Pipeline([\n",
    "                            \n",
    "      ( 'median',  MeanMedianImputer(imputation_method='median') ),\n",
    "\n",
    "      ( 'categorical_imputer', CategoricalImputer(imputation_method='frequent')),\n",
    "\n",
    "      ( \"ordinal\",OrdinalEncoder(encoding_method='arbitrary' )),    \n",
    "      \n",
    "      ( \"feat_scaling\",StandardScaler() )\n",
    "\n",
    "    ])\n",
    "\n",
    "  return pipeline_base\n",
    "\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  Next, we fit the pipeline to the train set and transformations to the validation and test set\n",
    "* So the pipeline can learn the transformations (in this case it is only feature scaling) from the train set, and apply the transformation to the other sets. \n",
    "* Let's visualize the first rows from the scaled data. Note it is a 2D NumPy array\n",
    "\n",
    "pipeline = pipeline_pre_processing()\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_val= pipeline.transform(X_val)\n",
    "X_test = pipeline.transform(X_test)\n",
    "\n",
    "X_train[:2,]\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Create Deep Learning Network\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  We will create a tensorflow model\n",
    "* We create a function that creates a sequential model, compiles the model and returns the model. The function needs the number of features the data has and  the number of neurons in the last layer\n",
    "* Let's define the network architecture\n",
    "  * We noted the data has 6 features. First, we will create a simple network just for a learning experience. \n",
    "  * The network is built using Dense layers - fully connected layers\n",
    "  * The input layer has the same number of neurons as the number of columns from the data. The activation function is relu. We parse the input_shape using a tuple.\n",
    "  * We are using 3 hidden layers, the first with 20 neurons, then 10 neurons, and the last with 5 neurons. Both will use relu as an activation function. This approach is the \"expansive-shrink\" option we mentioned in a previous notebook related to model architecture.\n",
    "  * After the input layer and each hidden layer, we have a dropout layer with a rate of 25% to reduce the chance of overfitting. \n",
    "* The output layer should reflect a multiclass classification.\n",
    "  * We set a dense layer, where the number of neurons used is the same as the number of classes in the target variable. This information is stored in a previously created variable - `n_labels`. \n",
    "  * For multiclass classification, we set the activation function as softmax, and we compile the model with adam as optimizer and loss function as categorical_crossentropy. We also set to monitor the metric accuracy.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "\n",
    "def create_tf_model(n_features, n_labels):\n",
    "\n",
    "  model = Sequential()\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Dense(units=n_features,activation='relu', input_shape=(n_features,)))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Dense(units=20,activation='relu'))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Dense(units=10,activation='relu'))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Dense(units=5,activation='relu'))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Dense(n_labels, activation='softmax'))\n",
    "  model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let's visualize the network structure\n",
    "\n",
    "model = create_tf_model(n_features=X_train.shape[1], n_labels=n_labels )\n",
    "model.summary()\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Once again, we can use `plot_model()` also from Keras.utils for a more graphical approach\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True)\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Fit the model\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Early stopping allows us to stop training when a monitored metric has stopped improving; this is useful to avoid overfitting the model to the data.\n",
    "* We will monitor the validation accuracy now \n",
    "  * We set patience as 10, which is the number of epochs with no improvement, after which training will be stopped. Although there is no fixed rule to set patience, if you feel that your model was learning still, then you stopped, you may increase the value and train again.\n",
    "  * We set the mode to min, since now we want the model to stop training when the loss didn't improve its performance, and improve means decrease\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We finally will fit the model\n",
    "* We create the model object and use `.fit()`, as usual\n",
    "  * We parse the Train set\n",
    "  * The epochs are set to 100. In theory, you may set a high value since we will add an early stop, which stops the training process when there is no training improvement. \n",
    "  * We parse the validation data using a tuple.\n",
    "  * Verbose is set to 1 so we can see in which epochs we are and the training and validation loss.\n",
    "  * Finally, we parse our callback as the early_stop object we created earlier.\n",
    "\n",
    "* For each epoch, note the training and validation loss and accuracy. Are they increasing? Decreasing? Static?\n",
    "  * Ideally, the loss should decrease as long as the epoch increases, showing a practical sign the network is learning. The accuracy should increase over the epochs.\n",
    "\n",
    "model = create_tf_model(n_features=X_train.shape[1],  n_labels=n_labels)\n",
    "\n",
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=100,\n",
    "          validation_data=(X_val, y_val),\n",
    "          verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "          )\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Model evaluation\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  Now we will evaluate the model performance by analyzing the train and validation losses and accuracy that happened during the training process. \n",
    "* In deep learning we use the model history to assess if the model learned, using the train and validation sets. We also evaluate separately how the model generalize on unseen data (on the test set)\n",
    "* The model training history information is stored in a `.history.history` attribute from the model. \n",
    "* **Note it shows loss and accuracy for train and validation**\n",
    "\n",
    "history = pd.DataFrame(model.history.history)\n",
    "history.head()\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We are plotting each loss and accuracy in a line plot, where the y-axis has the loss/accuracy value, the x-axis is the epoch number and the lines are colored by train or validation\n",
    "* We use `.plot(style='.-')` for this task\n",
    "  * Note the loss plot for training and validation data follow a similar path and are close to each other. It looks like the network learned the patterns.\n",
    "  * Note in the accuracy plot that both train and validation accuracies keep increasing. When the performance \"saturates\" for validation, the training stops, as we set the early stopping object.\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "history[['loss','val_loss']].plot(style='.-')\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "history[['accuracy','val_accuracy']].plot(style='.-')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Next, we will evaluate the model performance on the test set, using `.evaluate()` and parsing the test set. Note the value is not much different from the losses and accuracy in the train and validation set.\n",
    "* Note the loss is low and accuracy is high. It looks like the model learned the relationship between the features and the target, considering all features.\n",
    "\n",
    "model.evaluate(X_test,y_test)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> When evaluating a deep learning model, you typically cover the loss plot and evaluate the test set; however, **you can do this as an additional step** similar to the evaluation we did in conventional ML.\n",
    "* In classification, you would analyze the confusion matrix and classification report, using the custom function we have seen over the course.\n",
    "* One difference is that we readapted the function to evaluate also the validation set, but that is a minor change in the code; the overall logic is the same\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def confusion_matrix_and_report(X,y,pipeline,label_map):\n",
    "  # the prediction comes in a one hot encoded format\n",
    "  prediction = pipeline.predict(X)\n",
    "  # so we take the index from the highest probability, which is the \"winner\" or predicted class\n",
    "  prediction = np.argmax(prediction, axis=1)\n",
    "  \n",
    "  # we also take the index from the highest probability from the actual values\n",
    "  y = np.argmax(y, axis=1)\n",
    "  \n",
    "  print('---  Confusion Matrix  ---')\n",
    "  print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\n",
    "        columns=[ [\"Actual \" + sub for sub in label_map] ], \n",
    "        index= [ [\"Prediction \" + sub for sub in label_map ]]\n",
    "        ))\n",
    "  print(\"\\n\")\n",
    "\n",
    "  print('---  Classification Report  ---')\n",
    "  print(classification_report(y, prediction, target_names=label_map),\"\\n\")\n",
    "\n",
    "\n",
    "def clf_performance(X_train,y_train,X_test,y_test,X_val, y_val,pipeline,label_map):\n",
    "\n",
    "  print(\"#### Train Set #### \\n\")\n",
    "  confusion_matrix_and_report(X_train,y_train,pipeline,label_map)\n",
    "\n",
    "  print(\"#### Validation Set #### \\n\")\n",
    "  confusion_matrix_and_report(X_val,y_val,pipeline,label_map)\n",
    "\n",
    "  print(\"#### Test Set ####\\n\")\n",
    "  confusion_matrix_and_report(X_test,y_test,pipeline,label_map)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let's parse the values as usual.\n",
    "* Note the model is capable of separating the classes, including in the test set\n",
    "\n",
    "clf_performance(X_train, y_train,\n",
    "                X_test,y_test,\n",
    "                X_val, y_val,\n",
    "                model,\n",
    "                label_map= target_map.keys()\n",
    "                )\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Prediction\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let's take a sample from the test set and use it as if it was live data. We will consider 1 sample\n",
    "\n",
    "index = 1\n",
    "live_data = X_test[index-1:index,]\n",
    "live_data\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We use `.predict()` and parse the data. Note the result is not a direct 0, 1 or 2, but instead a probabilistic result for each class. \n",
    "\n",
    "  prediction_proba = model.predict(live_data)\n",
    "  prediction_proba\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> So we take the index from the highest probability, which is the \"winner\" or predicted class\n",
    "\n",
    "prediction_class = np.argmax(prediction_proba, axis=1) \n",
    "prediction_class\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let's plot the probabilistic result, so you can check the predictions in a more visual fashion\n",
    "* Read the pseudo-code\n",
    "* At the end you are getting `prediction_proba`, to define the associate probability for each class. Then you plot it in a bar plot using Plotly \n",
    "\n",
    "# create an empty dataframe, that will show the probability per class\n",
    "# we set that the probabilities as the prediction_proba\n",
    "prob_per_class= pd.DataFrame(data=prediction_proba[0],\n",
    "                             columns=['Probability']\n",
    "                             )\n",
    "\n",
    "# we round the values to 3 decimal points, for better visualization\n",
    "prob_per_class = prob_per_class.round(3)\n",
    "\n",
    "# we add a column to prob_per_class that shows the meaning of each class\n",
    "# in this case, the species name that are mapped in the target_map dict keys\n",
    "prob_per_class['Results'] = target_map.keys()\n",
    "\n",
    "prob_per_class\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We will use a bar plot, where x-axis shows the Result and the y-axis the associated probability for a given Result\n",
    "* I encourage you to go to the first cell of the Prediction section and change the index variable so that you would take a sample. Then you run all cells to predict until the plot from the cell below\n",
    "* You may change the index to another positive integer\n",
    "\n",
    "import plotly.express as px\n",
    "fig = px.bar(\n",
    "        prob_per_class,\n",
    "        x = 'Results',\n",
    "        y = 'Probability',\n",
    "        range_y=[0,1],\n",
    "        width=400, height=400,template='seaborn')\n",
    "fig.show()\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
