{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engine - Unit 08 - Create your own transformer\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%202%20-%20Unit%20Objective.png\"> Unit Objectives\n",
    "\n",
    "* Create your own transformer that can be arranged into a pipeline\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%204%20-%20Import%20Package%20for%20Learning.png\"> Import Package for Learning\n",
    "\n",
    "And load our typical packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Create your own transformer\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%206%20-%20Warning.png\"> What if, for your existing project, you couldn't find a built-in transformer that satisfies your project needs?\n",
    "* You can create a transformer. Your custom transformer will be a Python Class, which is a topic you are already familiar with!\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Before defining your custom transformer, all transformers in scikit-learn (and scikit-learn compatible libraries, like feature-engine) are implemented as Python classes, each with its own attributes and methods. \n",
    "* Our custom transformer (or Class) must be implemented as a class with the same methods, like fit(), transform(), fit_transform() etc. We will inherit these methods using two scikit-learn base classes: TransformerMixin and BaseEstimator. \n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> For that, we will need 2 base transformers from Scikit-learn. \n",
    "* `BaseEstimator`: According to the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html), it is a \"base class for all estimators in scikit-learn\". We will not focus on the technical aspects, only the frame, as it contains the core of what a transformer should have.\n",
    "* `TransformerMixin`: According to the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html) it is a Mixin class for all transformers in scikit-learn.\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "In feature-engine (and scikit-learn) we have a transformer that replaces the missing value with the mean. But let's imagine it didn't and we want to create `MyCustomTransformerForMeanImputation()`\n",
    "* Let's follow along to the code's comment to understand the steps\n",
    "\n",
    "import pandas as pd # to use .mean()\n",
    "\n",
    "# we will define 3 methods for the class: _init_, fit and transform\n",
    "# The fit_transform() will be inherited since we are using BaseEstimator and TransformerMixin\n",
    "\n",
    "# define your transformer name and as an argument inherit the base classes\n",
    "class MyCustomTransformerForMeanImputation(BaseEstimator, TransformerMixin):\n",
    "\n",
    "  #### here you define the variables you need to parse when you initialize the class\n",
    "  def __init__(self, variables):\n",
    "    # we make sure the variable will be a list, even if only one element\n",
    "    if not isinstance(variables, list): \n",
    "      self.variables = [variables]\n",
    "    else: self.variables = variables\n",
    "\n",
    "  #### here is where the learning happens. We perform the operation we are interested in,\n",
    "  #### in this case, calculate the mean\n",
    "  def fit(self, X, y=None):\n",
    "   \n",
    "    # we want to keep the mean value in a dictionary\n",
    "    self.imputer_dict_ = {}\n",
    "      \n",
    "    # loop over each variable, calculate the mean and save in the dictionary.  \n",
    "    for feature in self.variables:\n",
    "        self.imputer_dict_[feature] = X[feature].mean()\n",
    "    \n",
    "    return self\n",
    "\n",
    "  #### here you transform the variables based on what you learned in the .fit()\n",
    "  #### You can transform into the train set, test set or real-time data\n",
    "  def transform(self, X):\n",
    "    # loop over the variables and .fillna() in a given feature based on the \n",
    "    # mean of a given feature\n",
    "    for feature in self.variables:\n",
    "      X[feature].fillna(self.imputer_dict_[feature], inplace=True)\n",
    "      \n",
    "    return X\n",
    "\n",
    "You may create a custom transformer where you don't need to code the ``.fit().`` For example, imagine if you want to apply the upper case method to all the variables. You don't need to learn that; you just need to execute it.\n",
    "* Let's create this transformer and call `ConvertUpperCase()`\n",
    "\n",
    "# The comments relate to the new concepts for this exercise\n",
    "\n",
    "class ConvertUpperCase(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self, variables):\n",
    "    if not isinstance(variables, list): \n",
    "      self.variables = [variables]\n",
    "    else: self.variables = variables\n",
    "\n",
    "  # we don't need to learn anything here, we just return self\n",
    "  # we need to do that anyway to be compatible with scikit-learn format\n",
    "  def fit(self, X, y=None):\n",
    "      return self\n",
    "\n",
    "  # here we convert the variables using a method called .upper()\n",
    "  # We lopp over all the variables, check if it is an object, then use a lambda function...\n",
    "  # ...to apply .upper() to all rows\n",
    "  def transform(self, X):\n",
    "    for feature in self.variables:\n",
    "      if X[feature].dtype == 'object':\n",
    "        X[feature] = X[feature].apply(lambda x: x.upper())\n",
    "      else:\n",
    "        print(f\"Warning: {feature} data type should be object to use ConvertUpperCase()\")\n",
    "\n",
    "    return X\n",
    "\n",
    "We will use the penguin dataset. It has records for 3 different species of penguins, collected from 3 islands in the Palmer Archipelago, Antarctica. \n",
    "* We check for missing data\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv\"\n",
    "df = pd.read_csv(url)\n",
    "# df = sns.load_dataset('penguins')\n",
    "df.isnull().sum()\n",
    "\n",
    "And inspect the DataFrame\n",
    "\n",
    "df.head()\n",
    "\n",
    "We are interested to:\n",
    "* clean the missing data with `MyCustomTransformerForMeanImputation()` on the numerical variables and `CategoricalImputer()` for categorical variables\n",
    "* Next, we want to make all words from the 'sex' column upper case. We will use our own transformer: ConvertUpperCase()\n",
    "\n",
    "\n",
    "We set the pipeline using these rules and create 3 steps. Then we run `.fit_transform()`\n",
    "* Once we inspect the data with .head(), we notice the `'sex'` variable has all letters in upper case!\n",
    "\n",
    "from feature_engine.imputation import CategoricalImputer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "      ( 'custom_transf', MyCustomTransformerForMeanImputation(variables=['bill_length_mm',\n",
    "                                                                         'bill_depth_mm',\n",
    "                                                                         'flipper_length_mm',\n",
    "                                                                         'body_mass_g'] )),\n",
    "                     \n",
    "      ( 'categorical_imputer', CategoricalImputer(imputation_method='missing',\n",
    "                                                  fill_value='Missing',\n",
    "                                                  variables=['sex']) ),\n",
    "      \n",
    "      ('upper_case' , ConvertUpperCase(variables=['sex'])),\n",
    "])\n",
    "\n",
    "df_transformed = pipeline.fit_transform(df)\n",
    "df_transformed.head()\n",
    "\n",
    "Let's check if the numerical data is cleaned\n",
    "* It is cleaned!\n",
    "\n",
    "df_transformed.isnull().sum()\n",
    "\n",
    "We now check the mean values from the original data\n",
    "\n",
    "df[['bill_length_mm' , 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']].mean()\n",
    "\n",
    "And the learned mean values from `MyCustomTransformerForMeanImputation()` dictionary. We assess the 'custom_transf' steps, and check the attribute `.imputer_dict_`, which happens to be the dictionary we stored the mean values in the `.fit()` method \n",
    "\n",
    "pipeline['custom_transf'].imputer_dict_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
