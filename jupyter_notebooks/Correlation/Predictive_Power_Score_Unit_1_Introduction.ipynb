{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Power Score Unit \n",
    "\n",
    "## Lesson Learning Outcome\n",
    "\n",
    "* **Predictive Power Score Lesson is made of 1 unit.**\n",
    "* By the end of this lesson, you should be able to:\n",
    "  * Understand and interpret a PPS (predictive power score)\n",
    "  * Calculate and visualize PPS\n",
    "  * Combine PPS with Correlation Analysis \n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%202%20-%20Unit%20Objective.png\"> Unit Objectives\n",
    "\n",
    "* Understand and interpret a PPS (predictive power score)\n",
    "* Calculate and visualize PPS\n",
    "* Combine PPS with Correlation Analysis \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "The predictive power score detects linear or non-linear relationships between two variables. It helps to find predictive patterns in the data\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Question%20mark%20icon.png\n",
    "\"> **Why do we study Predictive power Scores?**\n",
    "  * Because PPS can be used as an alternative or in conjunction with correlation levels analysis.\n",
    "  * It is a handy library that will give additional insights into your data, including finding potential best univariate predictors for your target variable.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##  <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%203%20-%20Additional%20Learning%20Context.png\">  Additional Learning Context\n",
    "\n",
    "* We encourage you to:\n",
    "  * Add **code cells and try out** other possibilities, ie. play around with parameter values in a function/method, or consider additional function parameters etc.\n",
    "  * Also, **add your own comments** in the cells. It can help you to consolidate your learning. \n",
    "\n",
    "\n",
    "* Parameters in given function/method\n",
    "  * As you may expect, a given function in a package may contain multiple parameters. \n",
    "  * Some of them are mandatory to declare; some have pre-defined values, and some are optional. We will cover the most common parameters used/employed in Data Science for a particular function/method. \n",
    "  * However, you may find additional parameters in the respective package documentation, where you will find instructions on how to use a given function/method. The studied packages are open source, so this documentation is public.\n",
    "  * **For ppscore the link is [here](https://github.com/8080labs/ppscore)**.\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%204%20-%20Import%20Package%20for%20Learning.png\"> Import Packages for Learning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import ppscore as pps\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Predictive Power Score\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%205%20-%20Practice.png\"> According to its documentation, the PPS is an asymmetric, data-type-agnostic score that can detect linear or non-linear relationships between two columns. The score ranges from 0 (no predictive power) to 1 (perfect predictive power). It can be used as an alternative to correlation (matrix).\n",
    "\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Introduction\n",
    "\n",
    "You will probably start wondering during your project: what would be the relationship (linear or not) levels among my variables (features and target) regardless of the data type (you may transform categorical variables for correlation analysis, but it is an extra step)\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%205%20-%20Practice.png\"> Predictive Power Score is the answer to that! Each pair of variables in your dataset, regardless of its data type, calculates a score that tells **how a given variable has predictive power over another**. \n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> The calculation of PPS between variables considers one variable trying to predict another using a learning algorithm. \n",
    "The library fits an ML model for each pair of variables. \n",
    "* If the target is a continuous variable, the library uses a regression model and compares the performance (mean absolute error - MAE) to a naive regressor model (a model that always predicts the median). The PPS is the result of the following normalization (and never smaller than 0): `PPS = 1 - (MAE_model / MAE_naive)`\n",
    "* If the target is a categorical variable, the library fits a classifier and compares the performance (F1 score) to a naive classifier mode (always predicts the most common class). The PPS is the result of the following normalization (and never smaller than 0): `PPS = (F1_model - F1_naive) / (1 - F1_naive)`\n",
    "\n",
    "\n",
    "For additional clarification, you may check the [documentation](https://github.com/8080labs/ppscore#cases-and-their-score-metrics).\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Calculate PPS\n",
    "\n",
    "Let's generate some data to demonstrate how to use PPS, using NumPy capabilities\n",
    "* We will assume Y is our target variable, and X1 to X4 are features\n",
    "\n",
    "np.random.seed(seed=50)\n",
    "n_datapoints = 1000\n",
    "x = np.linspace(0, 10, n_datapoints)\n",
    "k = x * np.sin(x**2)\n",
    "u = np.cos(2*x) * np.sin(x)\n",
    "v = np.random.uniform(low=-10, high=5, size=n_datapoints)\n",
    "z = v * v + np.random.uniform(low=-1, high=2,size=n_datapoints)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data={\"Y\":k,\n",
    "                        \"X1\":x,\n",
    "                        \"X2\":np.random.choice(['Type A','Type B','Type C'], n_datapoints),\n",
    "                        \"X3\":v,\n",
    "                        \"X4\": z\n",
    "                        })\n",
    "df = df.head(300)\n",
    "df.head()\n",
    "\n",
    "Since the feature space is not extensive, we will do a Pairplot to quickly visualize the relationships among the variables\n",
    "* We notice patterns between Y and X1; and between X3 and X4 \n",
    "* We don't see X2, since it is a categorical variable (object type in the DataFrame) and it is not plotted in the Pairplot. If this variable was encoded as a number, it would appear.\n",
    "\n",
    "\n",
    "sns.pairplot(data=df)\n",
    "\n",
    "We calculate the PPS matrix with `pps.matrix()`, the documentation is [here](https://github.com/8080labs/ppscore#api). The argument is the dataset.\n",
    "* There is a computation cost to calculate the scores since the library will fit an ML model for each possible combination of variables, and the order is important, since the library calculates the score for X1 against X2 and X2 against X1, for example, In our exercise, it is expected to be a simple computation.\n",
    "* The result is a table. The variables we will be interested in are x, y, and ppscore.\n",
    "\n",
    "pps.matrix(df=df)\n",
    "\n",
    "We will then process this table to output a DataFrame where we can visualize the results\n",
    "* We create a `pps_matrix_raw` with `pps.matrix()`, then filter x, y and ppscore and do a pivot table on these filtered variables\n",
    "* The aspect is similar to a correlation table we saw earlier. As you may expect we can plot using a heatmap\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Here we see a practical aspect we mentioned earlier: pps is asymmetric, the pps between Y and X1 (that means X1 predicting Y) is 0.95, and the pps between X1 and Y (Y predicintg X1) is 0.44\n",
    "\n",
    "\n",
    "pps_matrix_raw = pps.matrix(df)\n",
    "pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
    "pps_matrix\n",
    "\n",
    "We create a custom heatmap function, using a threshold\n",
    "* You will notice there is a linecolor='lightgrey' that will create a grid in the plot; This makes sense for a PPS heatmap since typically there will be a good number of cells to look at, and a grid with sections helps with visualizing\n",
    "\n",
    "def heatmap_pps(df,threshold, figsize=(8,8), font_annot = 10):\n",
    "    if len(df.columns) > 1:\n",
    "\n",
    "      mask = np.zeros_like(df, dtype=np.bool)\n",
    "      mask[abs(df) < threshold] = True\n",
    "\n",
    "      fig, ax = plt.subplots(figsize=figsize)\n",
    "      ax = sns.heatmap(df, annot=True, annot_kws={\"size\": font_annot},\n",
    "                       mask=mask,cmap='rocket_r', linewidth=0.05,\n",
    "                       linecolor='lightgrey')\n",
    "      \n",
    "      plt.ylim(len(df.columns),0)\n",
    "      plt.show()\n",
    "\n",
    "\n",
    "Let's use our function on pps_matrix and set for now `threshold=0`\n",
    "* Next, we ask ourselves, how do I interpret it? I know the levels go from 0 to 1, but what is a \"good level\" of pps?\n",
    "* What should be the criteria to set a threshold for my analysis?\n",
    "\n",
    "heatmap_pps(df=pps_matrix, threshold=0)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> According to [this](https://github.com/8080labs/ppscore/issues/39) forum discussion, the interpretation depends on the context:\n",
    "\n",
    "* In general, it is hard to denote some specific levels and give some interpretation for them without knowing the context. For example, if many columns have a PPS of 0.3 then a PPS of 0.2 might actually not be that good. However, when no column has a PPS >0.01 then a PPS of 0.1 might be very good - especially when trying to predict something that is hard like stock prices.\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Nevertheless, there are some levels that are often helpful during everyday life:\n",
    "\n",
    "* PPS == 0 means that there is no predictive power\n",
    "* PPS < 0.2 often means that there is some relevant predictive power but it is weak\n",
    "* PPS > 0.2 often means that there is strong predictive power\n",
    "* PPS > 0.8 often means that there is a deterministic relationship in the data, for example, y = 3*x or there is some underlying if...else... logic\n",
    "\n",
    "* Based on those levels, it is often important to check the PPS for multiple columns and then determine your interpretation based on that.\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> **We shall consider levels from 0.2, however depending on the common levels for PPS in a given dataset, the threshold might be different**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* We will then calculate the range of common PPS values at `pps_matrix_raw`. Let's review this matrix first. \n",
    "\n",
    " \n",
    "\n",
    "pps_matrix_raw\n",
    "\n",
    "We will grab the ppscore column, and `filter values <1` (since values that equal 1 mean the score between a variable and itself). Then we calculate the summary statistics with `.describe()` and transpose it (for better table visualization).\n",
    "\n",
    "We are interested in the IQR - Q1 and Q3 values\n",
    "* In this case, the Q1 and Q3 ranges are 0 to 0. That means the majority of the values are zero. So for the first round of visualization, we will set the threshold at 0.15 (which allows us to see potential scores that would be closer to 0.2).\n",
    "\n",
    "pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
    "\n",
    "We set a threshold and now it is cleaner to analyze\n",
    "* There are two axes in the plot, y and x. The y-axis is the target variable in the PPS computation and the x-axis is the feature variable for PPS computation\n",
    "* We notice that:\n",
    "  * X1 has a very strong predictive power (deterministic relationship) to Y: 0.95.  That means if I have X1, I can easily predict Y\n",
    "  * On the other hand, if I have Y it is more difficult to predict X1. The PPS score is 0.44. Here there is a contextual interpretation, even 0.21 being a representative value in the dataset, the opposite relationship is much stronger (0.95); therefore, the predictive power of Y is weak to X1\n",
    "  * We see X3 and X4 have interesting PPS values among them. X3 has a strong predictive power (0.95) to X4. When you see the pair plot for these variables, this will be easy to conclude.\n",
    "  * However, X4 has lower (but still high) predictive power to X3.\n",
    "\n",
    "heatmap_pps(df=pps_matrix, threshold=0.15)\n",
    "\n",
    "---\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%205%20-%20Practice.png\"> **PRACTICE**\n",
    "\n",
    "Let's take the wine dataset. It shows records for three types of wines grown in the same region in Italy, made from a chemical analysis taken for different constituents found in the three types of wine.\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd\n",
    "\n",
    "data = load_wine()\n",
    "df_practice = pd.DataFrame(data.data,columns=data.feature_names)\n",
    "df_practice['wine_type'] = pd.Series(data.target)\n",
    "df_practice.head()\n",
    "\n",
    "\n",
    "Let's create the pps_matrix\n",
    "* What should be a good threshold level for the heatmap?\n",
    "\n",
    "pps_matrix_raw = pps.matrix(df_practice)\n",
    "pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
    "\n",
    "pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
    "\n",
    "Plot the heatmap for PPS\n",
    "* What are predictor variables that individually look to have predictive power to the target (wine type)?\n",
    "\n",
    "heatmap_pps(df=pps_matrix, threshold=0.15)\n",
    "\n",
    "You will need to type in the variables for the next exercise. Let's get the columns name, so we just copy and paste at `var_list`\n",
    "\n",
    "df_practice.columns\n",
    "\n",
    "Fill var_list with the 4 variables that showed predictive power to the target.\n",
    "* The code below will loop on each variable and do a box plot and swarmplot on each variable for each wine type.\n",
    "* Do these variables look to have predictive power to separate the wine types? (Pay attention to the distribution across each wine type)\n",
    "\n",
    "var_list = ['alcohol','ash','magnesium','total_phenols']  # list 4  variables\n",
    "for col in var_list:\n",
    "\n",
    "  fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,6))\n",
    "  sns.boxplot(data=df_practice, y=col, x='wine_type', ax=axes[0])\n",
    "  sns.swarmplot(data=df_practice, y=col, x='wine_type', dodge=True, ax=axes[1])\n",
    "  plt.show()\n",
    "  print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Combine with Correlation Study\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We are not interested in discussing if Correlation Analysis is better or not than PPS analysis. We want to use the best of both since they convey the data from different angles. Therefore, we want to combine both.\n",
    "\n",
    "\n",
    "We created custom functions where we combine a correlation analysis (considering Pearson and Spearman) and PPS, arranging the knowledge we built so far. There are two functions you need to call: \n",
    "* `CalculateCorrAndPPS()`: calculate correlation tables and PPS table for a dataset. This function prints Q1 and Q3 for PPS scores already.\n",
    "\n",
    "* `DisplayCorrAndPPS()`, the arguments are: `df_corr_pearson` which is the Pearson correlation table for the data, `df_corr_spearman` which is the Spearman correlation for the data, `pps_matrix` which is the PPS table for the data, and `CorrThreshold` and `PPS_Threshold`, which are visualization threshold for correlations and PPS respectively.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ppscore as pps\n",
    "\n",
    "def heatmap_corr(df,threshold, figsize=(20,12), font_annot = 8):\n",
    "  if len(df.columns) > 1:\n",
    "    mask = np.zeros_like(df, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    mask[abs(df) < threshold] = True\n",
    "\n",
    "    fig, axes = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
    "                linewidth=0.5\n",
    "                     )\n",
    "    axes.set_yticklabels(df.columns, rotation = 0)\n",
    "    plt.ylim(len(df.columns),0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def heatmap_pps(df,threshold, figsize=(20,12), font_annot = 8):\n",
    "    if len(df.columns) > 1:\n",
    "\n",
    "      mask = np.zeros_like(df, dtype=np.bool)\n",
    "      mask[abs(df) < threshold] = True\n",
    "\n",
    "      fig, ax = plt.subplots(figsize=figsize)\n",
    "      ax = sns.heatmap(df, annot=True, xticklabels=True,yticklabels=True,\n",
    "                       mask=mask,cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
    "                       linewidth=0.05,linecolor='grey')\n",
    "      \n",
    "      plt.ylim(len(df.columns),0)\n",
    "      plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def CalculateCorrAndPPS(df):\n",
    "  df_corr_spearman = df.corr(method=\"spearman\")\n",
    "  df_corr_pearson = df.corr(method=\"pearson\")\n",
    "\n",
    "  pps_matrix_raw = pps.matrix(df)\n",
    "  pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
    "\n",
    "  pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
    "  print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
    "  print(pps_score_stats.round(3))\n",
    "\n",
    "  return df_corr_pearson, df_corr_spearman, pps_matrix\n",
    "\n",
    "\n",
    "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix,CorrThreshold,PPS_Threshold,\n",
    "                      figsize=(20,12), font_annot=8 ):\n",
    "\n",
    "  print(\"\\n\")\n",
    "  print(\"* Analyze how the target variable for your ML models are correlated with other variables (features and target)\")\n",
    "  print(\"* Analyze multi colinearity, that is, how the features are correlated among themselves\")\n",
    "\n",
    "  print(\"\\n\")\n",
    "  print(\"*** Heatmap: Spearman Correlation ***\")\n",
    "  print(\"It evaluates monotonic relationship \\n\")\n",
    "  heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "  print(\"\\n\")\n",
    "  print(\"*** Heatmap: Pearson Correlation ***\")\n",
    "  print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
    "  heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "  print(\"\\n\")\n",
    "  print(\"*** Heatmap: Predictive power Score (PPS) ***\")\n",
    "  print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
    "        f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
    "  heatmap_pps(df=pps_matrix,threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "Call CalculateCorrAndPPS to calculate the necessary correlation/PPS tables\n",
    "\n",
    "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)\n",
    "\n",
    "Display in the heatmaps the correlation and PPS levels\n",
    "* The threshold value, either correlation or PPS, will be more trial and error to see what fits best. We started with a correlation threshold of 0.6 (strong correlation) and a PPS threshold of 0.15.\n",
    "* We set a small figsize since we don't have many variables\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Interpretations\n",
    "* When looking at the first 2 plots (linear and monotonic relationships), we note that X3 and X4 have a strong and negative linear and monotonic relationship.\n",
    "* When looking at the last plot, we note that X1 has a very strong predictive power (deterministic relationship) to Y. On the other hand, if I have Y it is more difficult to predict X1.\n",
    "* When looking at the last plot, we note that X3 has a strong predictive power to X4. However, X4 has lower (but still high) predictive power to X3. It shows a practical example of asymmetry.\n",
    "\n",
    "DisplayCorrAndPPS(df_corr_pearson=df_corr_pearson,\n",
    "                  df_corr_spearman=df_corr_spearman, \n",
    "                  pps_matrix=pps_matrix,\n",
    "                  CorrThreshold=0.6, PPS_Threshold=0.15,\n",
    "                  figsize=(5,5), font_annot=8)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
