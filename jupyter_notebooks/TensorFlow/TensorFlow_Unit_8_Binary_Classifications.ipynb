{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow - Unit 08 - Binary Classification\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%202%20-%20Unit%20Objective.png\"> Unit Objectives\n",
    "\n",
    "* Fit a deep learning neural network for Binary Classification task\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%204%20-%20Import%20Package%20for%20Learning.png\"> Import Package for Learning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Unit 08 - Binary Classification\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Workflow\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Challenge%20test.png\n",
    "\">\n",
    " We will follow the process used for supervised learning which we are familiar with, but now with a few tweaks:\n",
    "\n",
    "* Split the dataset into train, validation and test set\n",
    "* Create a pipeline to handle data cleaning, feature engineering and feature scaling\n",
    "* Create the neural network\n",
    "* Fit the pipeline to the train set and transformations to the other sets\n",
    "* Fit the model to the train and validation set\n",
    "* Evaluate the model\n",
    "* Prediction\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Load and split the data\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let's first load the data. We are using the breast cancer dataset from sklearn.\n",
    "* It shows records for a breast mass sample and a diagnosis informing whether it is malignant or benign cancer. The target variable is the diagnosis, where 1 is malignant, and 0 is benign.\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data,columns=data.feature_names)\n",
    "df['diagnosis'] = pd.Series(data.target)\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> As part of our workflow, we split the data, but now we will split it into train, validation, test sets. \n",
    "* First, we split into train and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train, y_test = train_test_split(\n",
    "                                    df.drop(['diagnosis'],axis=1),\n",
    "                                    df['diagnosis'],\n",
    "                                    test_size=0.2,\n",
    "                                    random_state=0\n",
    "                                    )\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)\n",
    "\n",
    "X_train\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Then, from the train set, we split a validation set. We set the validation set as 20% of the train set\n",
    "* Have a look at the print statement, which shows the amount of data we have in each set (train, validation and test)\n",
    "\n",
    "X_train, X_val,y_train, y_val = train_test_split(\n",
    "                                    X_train,\n",
    "                                    y_train,\n",
    "                                    test_size=0.2,\n",
    "                                    random_state=0\n",
    "                                    )\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape)\n",
    "print(\"* Validation set:\",  X_val.shape, y_val.shape)\n",
    "print(\"* Test set:\",   X_test.shape, y_test.shape)\n",
    "\n",
    "X_train\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Pipeline for data processing\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  We first create a pipeline for preprocessing the data. \n",
    "* In this case, it is only feature scaling.\n",
    "* We could have also added a step for removing correlated features, but let's keep it simple.\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "### Feat Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# in this case, we don't need data cleaning or feat eng\n",
    "def pipeline_pre_processing():\n",
    "  pipeline_base = Pipeline([\n",
    "      \n",
    "      ( \"feat_scaling\",StandardScaler() )\n",
    "\n",
    "    ])\n",
    "\n",
    "  return pipeline_base\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  Next, we fit the pipeline to the train set and transformations to the validation and test set\n",
    "* So the pipeline can learn the transformations (in this case it is only feature scaling) from the train set, and apply the transformation to the other sets. \n",
    "* Let's visualize the first rows from the scaled data. Note it is a 2D NumPy array\n",
    "\n",
    "pipeline = pipeline_pre_processing()\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_val= pipeline.transform(X_val)\n",
    "X_test = pipeline.transform(X_test)\n",
    "\n",
    "X_train[:2,]\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Create Deep Learning Network\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  We will create a tensorflow model\n",
    "* We create a function that creates a sequential model, compiles the model and returns the model. The function requires the number of features the data has to be used as the number of neurons for the first layer\n",
    "* Let's define the network architecture\n",
    "  * We noted the data has 30 features. We will create a simple network just for a learning experience. \n",
    "  * The network is built using Dense layers - fully connected layers\n",
    "  * The input layer has the same amount of neurons as the number of columns from the data. The activation function is relu. Finally, we parse the input_shape using a tuple.\n",
    "  * We are using 3 hidden layers, the first with 20 neurons, the next with 10 neurons and the last with 6 neurons. Both will use relu as an activation function.\n",
    "  * After the input layer and each hidden layer, we have a dropout layer with a 25% rate to reduce the chance of overfitting. In the previous notebook, we didn't add a dropout layer to the input layer. In this notebook, we are adding one to demonstrate it is possible. We covered the dropout layer in a previous notebook in case you want to refresh the concept.\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> The output layer should reflect binary classification.\n",
    "  * You may recall there are 2 ways to define an output layer for binary classification:\n",
    "    * Either with 1 neuron with sigmoid as activation function \n",
    "    * Or 2 neurons with softmax as activation function\n",
    "  * We will code both, so you can choose which one you would like to use\n",
    "* We compile the model depending on the output layer choice\n",
    "  * If it is 1 neuron with sigmoid as activation function: optimizer='adam', loss='binary_crossentropy'\n",
    "  * If it is 2 neurons with softmax as activation function: optimizer='adam', loss='categorical_crossentropy'\n",
    "\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  In classification tasks, we can use an additional metric when compiling: 'accuracy'. We will still monitor the loss (like we did in Regression), but now we can monitor the accuracy while training. \n",
    "* Note: in regression, we can add this argument since accuracy doesn't suit the context of regression\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  Below we find the model where the output layer has sigmoid as an activation function\n",
    "\n",
    "import os;\n",
    "import tensorflow as tf;\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2';\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "\n",
    "def create_tf_model_sigmoid(n_features):\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Dense(units=n_features,activation='relu', input_shape=(n_features,)))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Dense(units=20,activation='relu'))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Dense(units=10,activation='relu'))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Dense(units=5,activation='relu'))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  # note we use 1 neuron and sigmoid\n",
    "  model.add(Dense(units=1,activation='sigmoid'))\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  Below we find the model where the output layer has softmax as an activation function\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%206%20-%20Warning.png\"> In this exercise, we will move on with the model that has the activation function as sigmoid in the output layer, since in the next unit notebook, we will handle a network that has softmax as an activation function in the output layer \n",
    "* Even if you try to fit the model with softmax as an activation function in the output layer, it will not work since it needs an additional step. We need to one-hot-encode the target variable. We will do that in the next unit notebook, which covers multi-class classification.\n",
    "\n",
    "\n",
    "def create_tf_model_softmax(n_features):\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Dense(units=n_features,activation='relu', input_shape=(n_features,)))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Dense(units=20,activation='relu'))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Dense(units=10,activation='relu'))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Dense(units=5,activation='relu'))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  # note we use 2 neurons and softmax\n",
    "  model.add(Dense(2, activation='softmax'))\n",
    "  model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "  \n",
    "  return model\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let's visualize the network structure\n",
    "* Note the amount of parameters the network has, let's frist use `create_tf_model_sigmoid()`\n",
    "\n",
    "model = create_tf_model_sigmoid(n_features=X_train.shape[1])\n",
    "model.summary()\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Once again, we can use `plot_model()` also from Keras.utils for a more graphical approach\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let's check the difference between the structure of `create_tf_model_sigmoid()` and `create_tf_model_softmax()`\n",
    "* Below we plotted the model for `create_tf_model_softmax()` as you may expect, we defined the difference to be in the output layer\n",
    "\n",
    "model = create_tf_model_softmax(n_features=X_train.shape[1])\n",
    "plot_model(model, show_shapes=True)\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Fit the model\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Early stopping allows you to stop training when a monitored metric has stopped improving; this is useful to avoid overfitting the model to the data.\n",
    "* We will monitor the validation accuracy now \n",
    "  * We set patience as 10, which is the number of epochs with no improvement, after which the training will be stopped. Although there is no fixed rule to set patience, if you feel that your model was still learning when you stopped, you may increase the patience value and train again.\n",
    "  * We set the mode to max since now we want the model to stop training when the accuracy didn't improve its performance and improve means increase.\n",
    "  * When you are monitoring loss, the expectation is a decrease in loss over the training process. Therefore, in this case, you are looking for a minimum mode value; this is unlike accuracy as you expect an increase over the training time and thus monitor a max. \n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=10)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We finally will fit the model\n",
    "* We create the model object and use .fit(), as usual\n",
    "  * We parse the Train set\n",
    "  * Epochs are set to 75. In theory, you may set a high value since we will add an early stop, which stops the training process when there is no training improvement. \n",
    "  * We parse the validation data in a tuple.\n",
    "  * Verbose is set to 1 so we can see in which epochs we are and the training and validation loss.\n",
    "  * Finally, we parse our callback as the early_stop object we created earlier.\n",
    "\n",
    "* For each epoch, note the training and validation loss; are they increasing? Decreasing? Static?\n",
    "  * Ideally, it should decrease as long as the epoch increases, showing a practical sign the network is learning\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%206%20-%20Warning.png\"> In this exercise, we will move on with the model that has the activation function as sigmoid in the output layer, since in the next unit notebook, we will handle a network that has softmax as an activation function in the output layer \n",
    "* Even if you try to fit the model with softmax as an activation function in the output layer, it will not work since it needs an additional step. We need to one-hot-encode the target variable. We will do that in the next unit notebook, which covers multi-class classification.\n",
    "\n",
    "\n",
    "model = create_tf_model_sigmoid(n_features=X_train.shape[1])\n",
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=75,\n",
    "          validation_data=(X_val, y_val),\n",
    "          verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "          )\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Model evaluation\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  Now we will evaluate the model performance by analyzing the train and validation losses and accuracy that happened during the training process. \n",
    "* In deep learning we use the model history to assess if the model learned, using the train and validation sets. We also evaluate separately how the model generalize on unseen data (on the test set)\n",
    "* The model training history information is stored in a `.history.history` attribute from the model. \n",
    "* **Note it shows loss and accuracy for train and validation**\n",
    "\n",
    "history = pd.DataFrame(model.history.history)\n",
    "history.head()\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We are plotting each loss and accuracy in a line plot, where the y-axis has the loss/accuracy value, the x-axis is the epoch number and the lines are colored by train or validation\n",
    "* We use `.plot(style='.-')` for this task\n",
    "  * Note the loss plot for training and validation data follow a similar path and are close to each other. It looks the network learned the patterns.\n",
    "  * Note in the accuracy plot that both train and validation accuracies keep increasing; When the performance \"saturates\" for validation, the training stops, as we set in the early stopping object.\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "history[['loss','val_loss']].plot(style='.-')\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "history[['accuracy','val_accuracy']].plot(style='.-')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Next, we will evaluate the model performance on the test set, using `.evaluate()` and parsing the test set. Note the value is not much different from the losses and accuracy in the train and validation set.\n",
    "* Note the loss is low and accuracy is high. It looks like the model learned the relationship between the features and the target, considering all features.\n",
    "\n",
    "model.evaluate(X_test,y_test)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> When evaluating a deep learning model, you typically cover the loss plot and evaluate the test set; however, **if you want, you can do as an additional step** a similar evaluation we did in conventional ML.\n",
    "* In classification, you would analyze the confusion matrix and classification report, using the custom function we have seen over the course.\n",
    "* One difference is that we readapted the function to evaluate also the validation set, but that is a minor change in the code; the overall logic is the same\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%206%20-%20Warning.png\"> The adapted custom function below will work for the model made with a sigmoid as an activation function.\n",
    "* there is a difference in the prediction format between the sigmoid output layer and the softmax output layer, the first is a probabilistic output (between 0 and 1). In the next unit, we will cover this evaluation for a model with softmax\n",
    "* In case your model was trained with a softmax activation function, the code below may not work as expected\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def confusion_matrix_and_report(X,y,pipeline,label_map):\n",
    "  prediction = pipeline.predict(X).reshape(-1)\n",
    "  prediction = np.where(prediction<0.5,0,1) \n",
    "  # the prediction using sigmoid as acitvation function, is a probability number, between 0 and 1\n",
    "  # we convert it to 0 or 1, if it lower than 0.5, predicted class is 0, otherwise is 1\n",
    "  # you could change the threshold if you want.\n",
    "\n",
    "  print('---  Confusion Matrix  ---')\n",
    "  print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\n",
    "        columns=[ [\"Actual \" + sub for sub in label_map] ], \n",
    "        index= [ [\"Prediction \" + sub for sub in label_map ]]\n",
    "        ))\n",
    "  print(\"\\n\")\n",
    "\n",
    "\n",
    "  print('---  Classification Report  ---')\n",
    "  print(classification_report(y, prediction, target_names=label_map),\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "def clf_performance(X_train,y_train,X_test,y_test,X_val, y_val,pipeline,label_map):\n",
    "\n",
    "  print(\"#### Train Set #### \\n\")\n",
    "  confusion_matrix_and_report(X_train,y_train,pipeline,label_map)\n",
    "\n",
    "  print(\"#### Validation Set #### \\n\")\n",
    "  confusion_matrix_and_report(X_val,y_val,pipeline,label_map)\n",
    "\n",
    "  print(\"#### Test Set ####\\n\")\n",
    "  confusion_matrix_and_report(X_test,y_test,pipeline,label_map)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let's parse the values as usual.\n",
    "* Note the model is capable of separating the classes, including in the test set\n",
    "\n",
    "clf_performance(X_train, y_train,\n",
    "                X_test,y_test,\n",
    "                X_val, y_val,\n",
    "                model,\n",
    "                label_map= ['malignant', 'benign']\n",
    "                )\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Prediction\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let's take a sample from the test set and use it as if it was live data. We will consider 1 sample\n",
    "\n",
    "index = 1\n",
    "live_data = X_test[index-1:index,]\n",
    "live_data\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We use `.predict()` and parse the data. Note the result is not a direct 0 or 1, but instead a probabilistic result, between 0 and 1\n",
    "\n",
    "  prediction_proba = model.predict(live_data)\n",
    "  prediction_proba\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> You must decide a threshold when stating if the given probabilistic result is a 0 or 1. In this case, we set the threshold as 0.5\n",
    "* We converted using a NumPy function `np.where()`, where you make a condition (prediction_proba < 0.5), if that is true, it converts to 0; otherwise, it is 1.\n",
    "\n",
    "prediction_class = np.where(prediction_proba<0.5,0,1) \n",
    "prediction_class\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let's plot the probabilistic result, so you can check the predictions in a more visual fashion\n",
    "* Read the pseudo-code\n",
    "* At the end you are getting prediction_proba, to define the associate probability for the 2 classes: 0 and 1. Then you plot it in a bar plot using Plotly \n",
    "\n",
    "# define how you map the classes and the meaning of each\n",
    "# where the dict key is the class number\n",
    "target_map = {0:'Benign', 1:'Malignant'}\n",
    "\n",
    "# create an empty dataframe, that will show the probability per class\n",
    "# we set that the probabilities will be 0, but we will update soon\n",
    "prob_per_class= pd.DataFrame(\n",
    "        data=[0,0],\n",
    "        index=target_map.keys(),\n",
    "        columns=['Probability']\n",
    "    )\n",
    "\n",
    "\n",
    "# the summed predictions probabilities from both classes sum 1\n",
    "# for a binary classification case we can say that\n",
    "#    === if prediction_proba is, say, 0.01. that means the predicted class is 0\n",
    "#    so we can say the prediction probability from class 1 is 0.01 and for class 0 is 0.99\n",
    "#    ===  if prediction_proba is, say, 0.99. that means the predicted class is 1\n",
    "#    so we can say the prediction probability from class 1 is 0.99 and for class 0 is 0.01\n",
    "prob_per_class.iloc[1,0] = int(prediction_proba[0])\n",
    "prob_per_class.iloc[0,0] = 1 - int(prediction_proba[0])\n",
    "\n",
    "\n",
    "# we round the values to 3 decimal points, for better visualization\n",
    "prob_per_class = prob_per_class.round(3)\n",
    "\n",
    "# we add a column to prob_per_class that shows the meaning of each class\n",
    "# in this case, malignant or benign\n",
    "prob_per_class['Result'] = target_map.values() \n",
    "\n",
    "# take a look at the data we generated\n",
    "prob_per_class\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We will use a bar plot, where the x-axis shows the Result and the y-axis the associated probability for a given Result.\n",
    "* I encourage you to go to the first cell of the Prediction section and change the index variable so that you would take a sample. Then run all cells to predict until the plot from the cell below\n",
    "* You may change the index to another positive integer\n",
    "\n",
    "import plotly.express as px\n",
    "fig = px.bar(\n",
    "        prob_per_class,\n",
    "        x = 'Result',\n",
    "        y = 'Probability',\n",
    "        range_y=[0,1],\n",
    "        width=400, height=400,template='seaborn')\n",
    "fig.show()\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
