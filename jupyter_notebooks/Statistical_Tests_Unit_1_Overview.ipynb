{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Tests - Unit 01: Overview, Shapiro and Chi-Squared\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%201%20-%20Lesson%20Learning%20Outcome.png\"> Lesson Learning Outcome\n",
    "\n",
    "* **Statistical Tests Lesson is made of 3 units.**\n",
    "* By the end of this lesson, you should be able to:\n",
    "  * Understand and apply the concepts considered in a Statistical Test\n",
    "  * Conduct and interpret statistical tests like Shapiro Wilk, Chi Squared, T test, Paired T Test, ANOVA, Mann Whitney, Wilcoxon and Kruskal Wallis test\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%202%20-%20Unit%20Objective.png\"> Unit Objectives\n",
    "\n",
    "  * Understand and apply the concepts considered in a Statistical Test\n",
    "  * Conduct and interpret statistical tests using Shapiro Wilk and Chi Squared Test\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "* We will use Pandas and Pingouin (an open-source statistical package based mostly on Pandas and NumPy) libraries in this lesson.\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Question%20mark%20icon.png\n",
    "\">\n",
    " **Why do we study Statistical Tests?**\n",
    "  * Because we can determine the difference or similarity between groups. In addition, we can evaluate if a predictor variable has a statistical importance to a target variable.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%203%20-%20Additional%20Learning%20Context.png\"> Additional Context for Learning\n",
    "\n",
    "* We encourage you to:\n",
    "  * Add **code cells and try out** other possibilities, ie.: play around with parameters values in a function/method, or consider additional function parameters etc.\n",
    "  * Also, **add your own comments** to the cells. It can help you to consolidate the learning. \n",
    "\n",
    "* Parameters in given function/method\n",
    "  * As you may expect, a given function in a package may contain multiple parameters. \n",
    "  * Some of them are mandatory to declare; some have pre-defined values, and some are optional. We will cover the most common parameters used/employed at Data Science for a particular function/method. \n",
    "  * However, you may seek additional in the respective package documentation, where you will find instructions on how to use a given function/method. The studied packages are open source, so this documentation is public.\n",
    "  * **For Pandas the link is [here](https://pandas.pydata.org/) and for Pingouin is [here](https://pingouin-stats.org/api.html)**\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%204%20-%20Import%20Package%20for%20Learning.png\"> Import Package for Learning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import pingouin as pg\n",
    "import scipy\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Statistical Tests Overview\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> A statistical test has a mechanism to make a decision about a process. \n",
    "* **The idea is to see if there is enough evidence to accept or reject a hypothesis about the process.**\n",
    "\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Hypothesis Testing\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Hypothesis testing is a way of forming opinions or conclusions from the data we collected.\n",
    "\n",
    "* The data is used to choose between **two choices**, aka hypothesis or statements. In practical terms, the reasoning is done by comparing what we have observed to what we expected. \n",
    "* The available data will typically be a sample of the entire population.\n",
    "\n",
    "  * There is a **Null Hypothesis (H0)**, which consists of a statement about the sample data used. Typically it says there is no difference between groups.\n",
    "  * An **Alternative Hypothesis (H1)** is typically the research question and states that there is difference between groups.\n",
    "\n",
    "\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Significance Level\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> The Significance Level, or alpha, is the probability of rejecting the null hypothesis when it is true. \n",
    "* This means it is the percentage of risk we are fine to take while rejecting the null hypothesis.\n",
    "* This is a percentage that can be set by the researcher, however it is frequently set at 5%, meaning there is a 5 in 100 chance of rejecting the null hypothesis when it is in fact true.\n",
    "  * However, depending on the topic you are researching (typically, high stakes), you may be more conservative and select a lower alpha level. For example, if you are testing a new drug that will cure cancer, you want to be very sure about your conclusions\n",
    "\n",
    "\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Test Statistic\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> A Statistical test works by measuring a test statistic, which is a number that explains how different the relationship between your variables in your test is.\n",
    "* The method to calculate a test statistic varies between tests, for example, the formula for a test with 2 samples is different from a test with 3 samples. The test statistic compares differences between the samples.\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> P-value\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> The p-value is considered as a tool for deciding whether to reject the null hypothesis.\n",
    "\n",
    "* In a simple definition, a p-value is the probability that the null hypothesis is true. The smaller p-value is, stronger evidence we have in favor of the alternative hypothesis. We will not focus on how it is calculated, like which statistics table are used, let's keep simple for the moment.\n",
    "\n",
    "* Once you have a p-value and alpha (or Significance level), you are in a position to make a statistical conclusion and interpret a statistical test.\n",
    "  * If p-value is lower than alpha, you have enough evidence to reject the null hypothesis\n",
    "  * If the p-value is not lower than alpha, you do not have enough evidence to reject the null hypothesis\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Shapiro-Wilk\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\">  The Shapiro-Wilk tests if a given data is **normally distributed**\n",
    "* The null hypothesis states that the population is normally distributed.  The alternative hypothesis states that the population is not normally distributed\n",
    "* Thus, if the p-value is less than the chosen alpha level (typically set at 0.05), the null hypothesis is rejected, and there is evidence that the data tested is not normally distributed.\n",
    "\n",
    "\n",
    "First, let's generate some data to illustrate the concepts over the lesson, using the libraries we learned so far\n",
    "\n",
    "from scipy.stats import skewnorm\n",
    "np.random.seed(seed=1)\n",
    "size=200\n",
    "\n",
    "X1 = np.random.normal(loc=40, scale=2, size=int(size/2) )\n",
    "X2 = np.random.normal(loc=10, scale=4, size=int(size/2) ) \n",
    "bi_modal = np.concatenate([X1, X2])\n",
    "\n",
    "X1 = np.random.normal(loc=40, scale=4, size=int(size/4) )\n",
    "X2 = np.random.normal(loc=10, scale=4, size=int(size/4) ) \n",
    "X3 = np.random.normal(loc=0, scale=2, size=int(size/4) ) \n",
    "X4 = np.random.normal(loc=80, scale=2, size=int(size/4) ) \n",
    "multi_modal = np.concatenate([X1, X2, X3, X4])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data={'Normal':np.random.normal(loc=0, scale=2, size=size),\n",
    "                        \"Positive Skewed\": skewnorm.rvs(a=10, size=size),\n",
    "                        \"Negative Skewed\": skewnorm.rvs(a=-10, size=size),\n",
    "                        \"Exponential\":np.random.exponential(scale=20,size=size),\n",
    "                        \"Uniform\":np.random.uniform(low=0.0, high=1.0, size=size),\n",
    "                        \"Bimodal\":  bi_modal,\n",
    "                        \"Multimodal\":  multi_modal,\n",
    "                        \"Poisson\":np.random.poisson(lam=1.0, size=size),\n",
    "                        \"Discrete\": np.random.choice([10,12,14,15,16,17,20],size=size),\n",
    "                        }).round(3)\n",
    "\n",
    "df.head(3)\n",
    "\n",
    "\n",
    "Let's visualize the data distribution using boxplot and histogram for all variables\n",
    "* We loop on each variable and create a figure with 2 plots, one boxplot and one histogram\n",
    "\n",
    "for col in df.columns:\n",
    "  fig, axes = plt.subplots(nrows=2 ,ncols=1 ,figsize=(5,5), gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "  sns.boxplot(data=df, x=col, ax=axes[0])\n",
    "  axes[0].set_xlabel(\" \")\n",
    "  sns.histplot(data=df, x=col, kde=True, ax=axes[1])\n",
    "  fig.suptitle(f\"{col} Distribution - Boxplot and Histogram\")\n",
    "  plt.show()\n",
    "  print(\"\\n\\n\")\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We can test if all numerical columns in a DataFrame are normally distributed with `pg.normality()`.The function documentation is [here](https://pingouin-stats.org/generated/pingouin.normality.html). The arguments we parse are: `data`, `alpha=0.05` for the significance level\n",
    "* The output shows in the `index` each variable name, and at `normal` column the result if a given variable is normally distributed or not.\n",
    "\n",
    "pg.normality(data=df, alpha=0.05)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Note that in the previous example each column holds a distinct numerical distribution.\n",
    "* However your data may be in a different arragenment. If your data is in a long format, has numerical and categorical variables, and you want to know if the numerical variables are normally distributed based on a given category, you can use the `dv` and `group` arguments\n",
    "\n",
    "\n",
    "Consider the dataset below: It has records for 3 different species of penguins, collected from 3 islands in the Palmer Archipelago, Antarctica\n",
    "\n",
    "df_pinguins = sns.load_dataset('penguins')\n",
    "print(df_pinguins.shape)\n",
    "df_pinguins.head(3)\n",
    "\n",
    "You can check if `bill_length_mm` (numerical variable) is normally distributed across `species` (categorical variable)\n",
    "* We add the `dv` (dependent variable) as `bill_length_mm` and `group` (grouping variable) as `species`\n",
    "* We note that only `bill_length_mm` in `Gentoo` species is not normally distributed\n",
    "\n",
    "pg.normality(data=df_pinguins, dv='bill_length_mm', group='species', alpha=0.05)\n",
    "\n",
    "However, you will notice that `bill_length_mm` itself is not normally distributed\n",
    "\n",
    "pg.normality(data=df_pinguins['bill_length_mm'], alpha=0.05)\n",
    "\n",
    "You can plot a histogram for `bill_length_mm`, and `bill_length_mm` per `species` to make sense of the distribution plot/shape and the shapiro results\n",
    "* bill_length_mm variable is not normally distributed\n",
    "* when you analyze bill_length_mm per species, Gentoo's bill_length_mm is not normally distributed\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> **Note** The visuals may mislead you, what matters is the result from the statistical test\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,7))\n",
    "sns.histplot(data=df_pinguins, x='bill_length_mm', kde=True, ax=axes[0])\n",
    "sns.histplot(data=df_pinguins, x='bill_length_mm',hue='species' , kde=True, palette='Set2', ax=axes[1])\n",
    "plt.show();\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Chi-Squared Test (Goodness of Fit)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Chi-Squared Test measures if there is a significant difference between the expected frequencies and the observed frequencies in categorical variables\n",
    "\n",
    "\n",
    "* Hypothesis\n",
    "  * Null hypothesis â€“ there is no difference in the frequency or the proportion of occurrences in each category\n",
    "  * Alternate hypothesis - there is a difference in the frequency or proportion of occurrences in each category\n",
    "\n",
    "\n",
    "Let's consider a builtin dataset from pingouin. It is a study on heart disease, where the target equals one, which indicates heart disease.\n",
    "\n",
    "df = pg.read_dataset('chi2_independence')\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "Let's check target (heart disease) distribution with `.value_counts()`\n",
    "\n",
    "df['target'].value_counts()\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let's take target and fbs (that looks to define fasting blood sugar)\n",
    "* We ask ourselves, is fbs a good predictor for the target (heart disease)? Is there any significant association between them?\n",
    "\n",
    "Let's make a barplot to investigate `fbs` levels across different `target` levels\n",
    "* That shows the distribution of people that have/dont have heart disease and have/dont have fbs\n",
    "* It visually looks that the distribution of people with and without heart disease is similar to people with different fbs levels\n",
    "\n",
    "sns.countplot(x='fbs',hue='target',data=df)\n",
    "plt.show()\n",
    "\n",
    "We use `pg.chi2_independence()` to conduct Chi Square Test. The documentation link is [here](https://pingouin-stats.org/generated/pingouin.chi2_independence.html#pingouin.chi2_independence). The arguments we use are:\n",
    "* data, x and y as the variables for the chi squared test. y tends to be the target variable you are interested to analyze across a given feature (x)\n",
    "\n",
    "expected, observed, stats = pg.chi2_independence(data=df, x='fbs', y='target')\n",
    "\n",
    "The test summary (`stats`), has the result of the Pearson Chi-Square test\n",
    "\n",
    "\n",
    "stats\n",
    "\n",
    "We are interested on the `pval` from `pearson` test.\n",
    "* We ``query`` from stats where `test == pearson` and grab `pval`\n",
    "\n",
    "stats.query(\"test == 'pearson'\")['pval']\n",
    "\n",
    "We consider our significance level alpha = 0.05. \n",
    "* Since ``p-value`` (0.744428) is greater than alpha, we accept the null hypothesis.\n",
    "* Therefore there was not a significant association between `fbs` and `target`. \n",
    "  * `fbs` is not indicating to be a good predictor for `target`\n",
    "\n",
    "---\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Now let's take `target` and `sex`\n",
    "\n",
    "* We ask ourselves, is `sex` a good predictor for `target` (heart disease)?\n",
    "*  Is there any significant association between them?\n",
    "\n",
    "\n",
    "\n",
    "Let's make a barplot to investigate `sex` levels across different `target` levels\n",
    "* It visually looks that no heart disease (target = 0) proportion in one sex is different than the other.\n",
    "\n",
    "sns.countplot(data=df, x='sex', hue='target')\n",
    "plt.show()\n",
    "\n",
    "We conduct the Chi-Squared Test, where now `x='sex'`\n",
    "\n",
    "expected, observed, stats = pg.chi2_independence(data=df, x='sex', y='target')\n",
    "\n",
    "And extract p-value using the same rationale from previous exercise\n",
    "\n",
    "stats.query(\"test == 'pearson'\")['pval']\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We consider our significance level alpha = 0.05.\n",
    "* Since pvalue (0.000002) is smaller than alpha, we reject the null hypothesis.\n",
    "\n",
    "* Therefore there was significant association between `sex` and `target`.\n",
    "  *  `sex` is indicating to be a good predictor for `target` (heart disease)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
