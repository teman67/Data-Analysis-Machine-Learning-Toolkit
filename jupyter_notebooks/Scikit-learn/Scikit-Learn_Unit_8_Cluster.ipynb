{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn - Unit 08 - Cluster\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%202%20-%20Unit%20Objective.png\"> Unit Objectives\n",
    "\n",
    "* Understand how to group similar data using KMeans clustering algorithm\n",
    "* Explain Clusters profiles\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%204%20-%20Import%20Package%20for%20Learning.png\"> Import Package for Learning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "---\n",
    "\n",
    "## <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Scikit-learn - Unit 07 - Cluster\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Welcome to the world of unsupervised learning! It is slightly different than supervised learning, due to one aspect: there is no target variable. **The algorithm is left on its own and look for patterns in the data**\n",
    "* The ML task we will will study is called **cluster**, a type of unsupervised algorithm where it looks to group the data by similarity\n",
    "* The workflow used in cluster will be also slightly different than we used for regression and classification tasks, however you will still do tasks, like create pipeline steps, fit the pipeline using your data and evaluate the pipeline. But now they will be done in a different way\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%206%20-%20Warning.png\"> There are multiple clustering algorithms at Scikit learn, you may go to this [link](https://scikit-learn.org/stable/modules/clustering.html) and look for the potential algorithms to learn and use over your career. \n",
    "* We will study **KMeans** in this course, since it is a starting point for your career and will not add much complexity to what we have been studying so far. In case you want to refresh the concepts of KMeans, you may revert to Module 2 - ML Essentials \n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Workflow\n",
    "\n",
    "#### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Introduction\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> In practical terms, we don't know for sure how good your cluster model performance will be\n",
    "* Unless you gather a separate data and find a way to discover the actual value, so you can compare to the cluster prediction. This is not so trivial in practical terms and in this course we will not consider this alternative.\n",
    "* That being said, you will not know, for sure for example, if a pipeline with 4 clusters is in reality better than a pipeline with 7 clusters. However, there are approaches you can use to frame the project and reach more conclusive results that will make you to understand the patterns in your data.\n",
    "\n",
    "---\n",
    "\n",
    "#### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Expectation and Pipeline Objective\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Tips.png\n",
    "\"> This notebook, is dense and we cover many concepts. But always remember the core concept of this notebook is simple:\n",
    "* **Fit a Cluster Pipeline that groups similar data and explain each Cluster profile**\n",
    "\n",
    "---\n",
    "\n",
    "#### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Major ideas\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Challenge%20test.png\n",
    "\"> The major ideas  we consider in this notebook are:\n",
    "* 1: **Create Cluster pipeline**. Before fitting the pipeline, we need to define the number of PCA components and number of cluster.\n",
    "* 2: **Fit the Cluster Pipeline**\n",
    "* 3: We need to **understand Cluster profile**. We will use a classifier where the target is the cluster prediction to identify the most important variables that define a cluster\n",
    "* 4: **Cluster analysis**: explain each cluster profile in terms of the most important variables. In addition, in case your dataset has a separate variable you want to study and you didn't include in the cluster pipeline, you can study how this variable correlates to the clusters. In our case, we will analyze the clusters and the diagnostic (malignant or benign) \n",
    "\n",
    "---\n",
    "\n",
    "#### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Practical Workflow\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Steps.png\n",
    "\"> However, the practical workflow we will code is longer, and it is based on the major ideas we saw above. In particular, in this notebook we will:\n",
    "* 1 - **Create a Cluster Pipeline** that contains the following steps: data cleaning, feature engineering, feature scaling, PCA and Cluster Model (KMeans). Note: this pipeline has parameters for PCA and Cluster that we will need to update over the notebook.\n",
    "* 4 - Conduct an analysis to determine the  number of components in a PCA. We will update that into the Cluster Pipeline\n",
    "* 5 - Apply **Elbow Method and evaluate Silhoutte score**, to define the number of clusters in Cluster Pipeline\n",
    "* 7 - **Fit** the Cluser pipeline\n",
    "* 8 - Add cluster predictions to the data\n",
    "* 9 - Create a separate **Classifier Pipeline**, where target variable is clusters predictions and features are remaining variables\n",
    "* 10 - Fit this classifier, evaluate performance and assess most important features. These features are the most **important features to define the clusters predictions**\n",
    "* 11 - **Cluster analysis**: explain each cluster profile in terms of the most important features from previous step. In addition, in case your dataset has a separate variable you want to study and you didn't include in the cluster pipeline, you can study how this variable correlates to the clusters \n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Load Data\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Let's load the breast cancer data from sklearn. It shows records for a breast mass sample and a diagnosis informing whether it is as malignant or benign cancer, where 0 is malignant, 1 is benign.\n",
    "* **Our objective is to cluster similar datapoints, and after analyze the clusters against the diagnostic (malignant or benign)**\n",
    "  * As a result, **we will use only the 30 features** (all variables but Diagnostic) to fit the cluster pipeline.\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%206%20-%20Warning.png\"> We know in advance this dataset has only numerical feaures and no missing data.\n",
    "* We are adding on purpose missing data (`np.NaN`) in the first 10 rows of 'mean smoothness' using `.iloc[:10,4]`, just to better simulate the datasets you will likely face in the workplace\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data,columns=data.feature_names)\n",
    "df.iloc[:10,4] = np.NaN\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> ML Pipeline for Cluster\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> The Cluster Pipeline is made of Data Cleaning (mediam imputation on `mean smoothness`) feature scaling, PCA and model (KMeans) steps\n",
    "* Note: `n_components` of PCA and `n_clusters` of KMeans values will be updated afterwards, for now we leave arbitrary numbers of 50 (it could be any number)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "### Data Cleaning\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "\n",
    "### Feat Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "### PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "### ML algorithm\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def PipelineCluster():\n",
    "  pipeline_base = Pipeline([\n",
    "                            \n",
    "      ( 'MeanMedianImputer', MeanMedianImputer(imputation_method='median',\n",
    "                                               variables=['mean smoothness']) ),\n",
    "\n",
    "      (\"scaler\", StandardScaler()  ),    \n",
    "\n",
    "      (\"PCA\",  PCA(n_components=50, random_state=0)), \n",
    "\n",
    "      (\"model\", KMeans(n_clusters=50, random_state=0)  ), \n",
    "  ])\n",
    "  return pipeline_base\n",
    "\n",
    "PipelineCluster()\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Principal Component Analysis (PCA)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Principal Component Analysis, or PCA, is a transformation to your data and attempts to find out what features explain the most variance in your data.\n",
    "* PCA reduces the number of variables, while it preserves as much information as possible. After the transformation, it creates a set of components, where each component contains the relevant information from the original variables.\n",
    "* **This is useful in a Cluster pipeline since it is a method to reduce the feature space and provide a data to the model that is in a better format for the algorithm to group similar data**.\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We are interested to find the most suitable `n_components`, then we update the value on ML Pipeline for Cluster\n",
    "* To reach that, we will create an object based on PipelineCluster(), then remove the last 2 steps (PCA and model): `.steps[:-2]`\n",
    "* At the end, the `pipeline_pca` scales the data, so we can apply PCA afterwards\n",
    "\n",
    "pipeline_cluster = PipelineCluster()\n",
    "pipeline_pca = Pipeline(pipeline_cluster.steps[:-2])\n",
    "df_pca = pipeline_pca.fit_transform(df)\n",
    "\n",
    "print(df_pca.shape,'\\n', type(df_pca))\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Next we apply PCA separately to the scaled data. Similarly to what we did on previous unit notebook.\n",
    "* Next we are interested to define the number of components from PCA step. We will set the number of components as the number of columns the scaled data has, in this case, 30. That is useful in understanding the explained variance of each component.\n",
    "* The interpretation is similar from previous notebook\n",
    "  * The first three components are more significant than the others. And, together, they sum 72.47% of the data variance. That is okay. It is a good sign when in a few components, like 3 or 4, you can get more than 80% of your data variance. So you could select three as the number of components, which is good progress since you had 30 features and now have three components.\n",
    "  * But in this exercise, for learning purposes, we will aim for more than 90% of data variance and use seven components since we could get more data variance with a relatively low increase of components.\n",
    "\n",
    "n_components = 30 # set the number of components as all columns in the data\n",
    "\n",
    "pca = PCA(n_components=n_components).fit(df_pca)  # set PCA object and fit to the data\n",
    "x_PCA = pca.transform(df_pca) # array with transformed PCA\n",
    "\n",
    "\n",
    "# the PCA object has .explained_variance_ratio_ attribute, which tells \n",
    "# how much information (variance) each component has \n",
    "# We store that to a DataFrame relating each component to its variance explanation\n",
    "ComponentsList = [\"Component \" + str(number) for number in range(n_components)]\n",
    "dfExplVarRatio = pd.DataFrame(\n",
    "    data= np.round(100 * pca.explained_variance_ratio_ ,3),\n",
    "    index=ComponentsList,\n",
    "    columns=['Explained Variance Ratio (%)'])\n",
    "\n",
    "# prints how much of the dataset these components exaplain (naturally in this case will be 100%)\n",
    "PercentageOfDataExplained = dfExplVarRatio['Explained Variance Ratio (%)'].sum()\n",
    "\n",
    "print(f\"* The {n_components} components explain {round(PercentageOfDataExplained,2)}% of the data \\n\")\n",
    "print(dfExplVarRatio)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> In the next cell we just copied the code from the cell above and changed `n_components` to 7.\n",
    "  * With 7 components we achieved a bit more than 90% of data variance\n",
    "\n",
    "n_components = 7\n",
    "\n",
    "pca = PCA(n_components=n_components).fit(df_pca)\n",
    "x_PCA = pca.transform(df_pca)\n",
    "\n",
    "ComponentsList = [\"Component \" + str(number) for number in range(n_components)]\n",
    "dfExplVarRatio = pd.DataFrame(\n",
    "    data= np.round(100 * pca.explained_variance_ratio_ ,3),\n",
    "    index=ComponentsList,\n",
    "    columns=['Explained Variance Ratio (%)'])\n",
    "\n",
    "PercentageOfDataExplained = dfExplVarRatio['Explained Variance Ratio (%)'].sum()\n",
    "\n",
    "print(f\"* The {n_components} components explain {round(PercentageOfDataExplained,2)}% of the data \\n\")\n",
    "print(dfExplVarRatio)\n",
    "\n",
    "Next we rewrite the `PipelineCluster()`, updating `n_components` to 7\n",
    "* Note, in a real project, you don't have to necessarly rewrite in the cell below the pipeline. You could have scrolled up until the cell where we defined previously the pipeline and update there. But for learning purposes, we rewrite the pipeline the cell below \n",
    "\n",
    "def PipelineCluster():\n",
    "  pipeline_base = Pipeline([\n",
    "                            \n",
    "      ( 'MeanMedianImputer', MeanMedianImputer(imputation_method='median',\n",
    "                                               variables=['mean smoothness']) ),\n",
    "\n",
    "      (\"scaler\", StandardScaler()  ),    \n",
    "\n",
    "      (\"PCA\",  PCA(n_components=7, random_state=0)),  ##### we update the n_components to 7\n",
    "\n",
    "      (\"model\", KMeans(n_clusters=30, random_state=0)  ), \n",
    "  ])\n",
    "  return pipeline_base\n",
    "\n",
    "PipelineCluster()\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Elbow Method and Silhoutte Score\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We are now interested to find the most suitable `n_clusters`, then we update the value on ML Pipeline for Cluster\n",
    "* But how do you know the optimal amount of clusters to your data?\n",
    "* **We will combine 2 techniques (Elbow Method and Silhoutte Score) to find the optimal value for number of cluster**. Both will suggest values and we will use them in conjuction to make a decision on the optimal amount of clusters\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Tips.png\n",
    "\">\n",
    " We will first explain and apply Elbow. Then we will explain and apply Silhouette score.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Challenge%20test.png\n",
    "\">  There is a technique called Elbow Method. According to [Yellowbrick documentation](https://www.scikit-yb.org/en/latest/api/cluster/elbow.html) - (a ML visualization library), the elbow method runs k-means clustering on the dataset for a range of values for k and then for each value of k computes an average score for all clusters. By default, the distortion score is computed, the sum of square distances from each point to its assigned center\n",
    "   \n",
    "* That is plotted as a line chart, where on x axis you find the values for amount of clusters and in the y axis the distortion score. The line chart will remind you an arm, then you will picj the point of inflection (or the elbow) as the optimal value to number of clusters.\n",
    "  * According to [Wikipedia](https://en.wikipedia.org/wiki/Elbow_method_(clustering)), using the \"elbow\" or \"knee of a curve\" as a cutoff point is a common heuristic in mathematical optimization to choose a point where diminishing returns are no longer worth the additional cost. In clustering, this means one should choose a number of clusters so that adding another cluster doesn't give much better modeling of the data.\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Prepare data for analysis\n",
    "  * You need to transform your data up to the point that it will hit the model, for Elbow Method and Silhouette score. \n",
    "    * Therefore we remove the last step (`.steps[:-1]`) and fit_transform `pipeline_analysis` to the data\n",
    "    * Note the data has 7 columns, since passed through PCA step\n",
    "\n",
    "pipeline_cluster = PipelineCluster()\n",
    "pipeline_analysis = Pipeline(pipeline_cluster.steps[:-1])\n",
    "df_analysis = pipeline_analysis.fit_transform(df)\n",
    "\n",
    "print(df_analysis.shape,'\\n', type(df_analysis))\n",
    "\n",
    "Next we use [`KElbowVisualizer()`](https://www.scikit-yb.org/en/latest/api/cluster/elbow.html) from YellowbrickElbow Analysis to implement the Elbow Method\n",
    "* We parse the algorithm we want (KMeans) and the range of number of clusters we want to try, in this case from 1 to 10, so we parse in a tuple of (1,11), where the last value is not inclusive. \n",
    "* Here there is no fixed recipe, you have to try few ranges of number of clusters. Typically you may try initially a range of 1 to 10, or 1 to 15 and refine accordingly.\n",
    "* Then we fit this object to the `df_elbow` (the data that passed through data cleaning, feature scaling and PCA)\n",
    "  * **Note the plot suggests 3 clusters!**\n",
    "\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "visualizer = KElbowVisualizer(KMeans(random_state=0), k=(1,11))\n",
    "visualizer.fit(df_analysis) \n",
    "visualizer.show() \n",
    "plt.show()\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Challenge%20test.png\n",
    "\"> There is also **Silhouette score** that help us to define the number of clusters. You can revert to Module 2 where we presented the concept int the performance metric video.\n",
    "\n",
    "* The silhouette score **interprets and validates the consistency within clusters**, which is based on the mean intra-cluster distance and mean nearest-cluster distance for each data point.\n",
    "  * The mean intra-cluster distance is the average distance between the data point and all other data points in the same cluster. Essentially, how far each data point is from the center of its own cluster. \n",
    "  * The mean nearest-cluster distance on the other hand is the average distance between the data point and all other data points of the next nearest cluster. In other words, how far each data point in 1 cluster is to the center of its nearest neighbouring cluster.\n",
    " \n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> The silhouette score range is from -1 to +1, where:\n",
    "  *   “+1” means that a clustered data point is dense and properly separated from other clusters. \n",
    "  * A score close to 0 means the clustered data point is overlapping with another cluster.  \n",
    "  * A negative score means that the clustered data point may be wrong; it may even belong to another cluster.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Tips.png\n",
    "\">\n",
    " The silhoutte score for each data point allows you to build a Silhoutte plot, showing each silhoutte score for each data point across all clusters.\n",
    "* You can then calculate an **average silhoutte score** for the plot. This average helps to (1) compare different models with different number of clusters and (2) define a performance metric to a given cluster model. A rule of thumb in the industry is that average silhoutte score greater than 0.5 means the clusters are nicely separated, but there may be a case where for your dataset the optimal amount of cluster leads to a averge lower than 0.5. This is fine also, it just means we computed for that particular dataset the optimal way to cluster it even though it doesn't have a tremendous great silhoutte score.\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> To evaluate clusters silhouete we need the data in a format before it hits the model, we have done this already and the result is stored at `df_analysis`\n",
    "* We will use [SilhouetteVisualizer](https://www.scikit-yb.org/en/latest/api/cluster/silhouette.html) and [KElbowVisualizer](https://www.scikit-yb.org/en/latest/api/cluster/elbow.html) from Yellowbrick\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> The code logic has 2 moments\n",
    "* **First you will calculate the average silhoutte score for different number of clusters** using  KElbowVisualizer() by setting KMeans() as the algorithm,  the range 2 to 11 of number of clusters (it doesn't accept 1 cluster) and the  metric='silhouette'. Then you will fit to the scaleddata (df_analysis) and show the results\n",
    "  * You will evalute which number of clusters produce higher average silhoutte score\n",
    "* Then you will iterate on the **silhouette plot for models with different number of clusters**, in this case from 2 to 11. You will use SilhouetteVisualizer() and set the estimator as KMeans(). Then you will fit to the scaleddata (df_analysis) and show the results\n",
    "  *  You will evaluate if the silhouette values are varying too much in the cluster, if there are too many values lower than the average silhouette, if there are too many negative sihouette values.\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Note the following:\n",
    "* Average Silhouette Score: best result is with 2 clusters, but 3 is not that far away. We will give more attention to evalute the Silhouette Plot from these options. \n",
    "* Silhouette Plot:\n",
    "  * 2 clusters: there is one cluster that is dominant (the blue) since it is more frequent and the majority of its value is greater than the average score (the red dotted line). The other cluster (green) has few data points with negative score (these may belong to other cluster) and almost no data point is above the average score.\n",
    "\n",
    "  * 3 clusters: there is one cluster that is dominant (the blue) since it is more frequent and the majority of its value is greater than the average score (the red dotted line). the other 2 clusters look to have similar frequency. The blue cluster has few datapoints greater than the average and little negative silhouette values. However, the green cluster has few data points with negative score (these may belong to other cluster) and almost no data point is above the average score.\n",
    "\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "print(\"=== Average Silhouette Score for different number of clusters ===\")\n",
    "visualizer = KElbowVisualizer(KMeans(random_state=0), k=(2,7), metric='silhouette')\n",
    "visualizer.fit(df_analysis) \n",
    "visualizer.show() \n",
    "plt.show()\n",
    "print(\"\\n\")\n",
    "\n",
    "for n_clusters in np.arange(start=2,stop=11):\n",
    "  \n",
    "  print(f\"=== Silhoutte plot for {n_clusters} Clusters ===\")\n",
    "  visualizer = SilhouetteVisualizer(estimator = KMeans(n_clusters=n_clusters, random_state=0),\n",
    "                                    colors = 'yellowbrick')\n",
    "  visualizer.fit(df_analysis)\n",
    "  visualizer.show()\n",
    "  plt.show()\n",
    "  print(\"\\n\")\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%208-%20Challenge.png\"> What is the number of clusters then?\n",
    "* Elbow Method says 3\n",
    "* Average Silhouette Score says 2, but Silhoutte Plot from 3 clusters is better than 2 clusters.\n",
    "* As a result, we will pick 3, since the Eblow Method and Silhoutte Plot supports that decisions\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Next we rewrite the `PipelineCluster()`, updating `n_cluster` to 3\n",
    "* Note, in a real project, you don't have to necessarly rewrite in the cell below the pipeline. You could have scrolled up until the cell where we defined previously the pipeline and update there. But for learning purposes, we rewrite the pipeline the cell below \n",
    "\n",
    "def PipelineCluster():\n",
    "  pipeline_base = Pipeline([\n",
    "                            \n",
    "      ( 'MeanMedianImputer', MeanMedianImputer(imputation_method='median',\n",
    "                                               variables=['mean smoothness']) ),\n",
    "\n",
    "      (\"scaler\", StandardScaler()  ),    \n",
    "\n",
    "      (\"PCA\",  PCA(n_components=7, random_state=0)), \n",
    "\n",
    "      (\"model\", KMeans(n_clusters=3, random_state=0)  ),  ##### update n_clusters to 3 \n",
    "  ])\n",
    "  return pipeline_base\n",
    "\n",
    "PipelineCluster()\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Tips.png\n",
    "\"> Notice the additional effort and steps we take in clustering and compare to the workflow we have for Classification and Regression. Just now we are read to train the pipeline.\n",
    "  * Note we have only 1 pipeline and we are not doing hyperparameter optimization when training the model\n",
    "  * We \"kind\" of made a hyperparameter optimization in the previous sections, since we were trying different options for PCA components and number of clusters for KMeans().\n",
    "  * Let's fit the pipeline then!\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Fit Cluster Pipeline\n",
    "\n",
    "We don't need to split our data. All available data is used for training. \n",
    "* For training purposes, we create a DataFrame `X` that is a copy of your data.\n",
    "\n",
    "X = df.copy()\n",
    "print(X.shape)\n",
    "X.head(3)\n",
    "\n",
    "Then we fit Cluster pipeline to the training data (`X`)\n",
    "\n",
    "pipeline_cluster = PipelineCluster()\n",
    "pipeline_cluster.fit(X)\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Add cluster predictions to dataset\n",
    "\n",
    "We add a column \"`Clusters`\" (with the Cluster Pipeline predictions) to X\n",
    "* Scroll to the right and check the last variable. That is the clusters predicitons for each datapoint of your dataset\n",
    "* The model predictions are stored in an attribute `.labels_`\n",
    "* Since the model is in a pipeline, you will grab using the notation `pipeline_cluster['model'].labels_`\n",
    "\n",
    "X['Clusters'] = pipeline_cluster['model'].labels_\n",
    "print(X.shape)\n",
    "X.head(3)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Next we are interested to know the cluster frequency\n",
    "* Note there are 3 clusters, and the counting starts from 0.\n",
    "* We note that the algorithm found in the dataset that the majority of the data (63%) belong to cluster number 2, where the remaining datapoints share equally the other 2 clusters.\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Tips.png\n",
    "\">  **But what is the profile of each cluster?**\n",
    "\n",
    "\n",
    "print(f\"* Clusters frequencies \\n{ X['Clusters'].value_counts(normalize=True).to_frame().round(2)} \\n\\n\")\n",
    "X['Clusters'].value_counts().sort_values().plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Fit a classifier, where target is cluster predictions and features remaining variables\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We are in a moment where we have clusters predictions made from the cluster pipeline, but we can't interpret the clusters yet. \n",
    "\n",
    "\n",
    "We are **interested to learn the profile from each cluster**, based on the most relevant dataset variables.\n",
    "* Our new dataset has `Clusters` as a variable. We are using a technique where  `Clusters` will be the **target for a classifier**, and the remaining variables will be features to that target.\n",
    "  * We will assume that the most relevant features for this classifier, will be the most relevant variables that define a cluster.\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Challenge%20test.png\n",
    "\">\n",
    " To do that, we will use the traditional workflow we covered in the previous notebooks: \n",
    " * 1 - split the data in train and test set\n",
    " * 2 - create the classifier pipeline\n",
    " * 3 - fit the classifier to training data\n",
    " * 4 - evaluate pipeline performance\n",
    " * 5 - and (most important for our analysis) **assess feature importance**.\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Question%20mark%20icon.png \"> Note: If you need, pause for a second and reflect in which step from the \"Major ideas\" section we are. That may help you to better understand our goal, which moment we are now and the next step to move on.\n",
    "\n",
    "\n",
    "We start by copying `X` to a DataFrame `df_clf`\n",
    "\n",
    "df_clf = X.copy()\n",
    "print(df_clf.shape)\n",
    "df_clf.head(3)\n",
    "\n",
    "Next we split train and test sets, where the target variable is `'Clusters'`\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train, y_test = train_test_split(\n",
    "                                    df_clf.drop(['Clusters'],axis=1),\n",
    "                                    df_clf['Clusters'],\n",
    "                                    test_size=0.2,\n",
    "                                    random_state=0\n",
    "                                    )\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Create a classifier pipeline \n",
    "* We should use the **data cleaning and feature engineering** steps from the Cluster Pipeline.\n",
    "* Then we add the conventional steps for supervised learning: **feature scaling, feature selection and modelling**\n",
    "* We are considering a model that typically offers good results and features importance can be assessed with `.features_importance_` using a tree based algorithm. We are using GradientBoostingClassifier since it typically has good performance while it is fast to train.\n",
    "  * We could conduct a detailed hyperparameter optimization to find the best tree based model, but we are most interested here to find a pipeline that can explain the relationship between the target (Clusters) and the features, so we can assess the feature importance afterwards.\n",
    "\n",
    "### Feat Selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "### ML algorithm\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "\n",
    "def PipelineClf2ExplainClusters():\n",
    "  pipeline_base = Pipeline([\n",
    "                            \n",
    "      ( 'MeanMedianImputer', MeanMedianImputer(imputation_method='median',\n",
    "                                               variables=['mean smoothness']) ),\n",
    "\n",
    "      (\"scaler\", StandardScaler()  ),    \n",
    "\n",
    "      (\"feat_selection\", SelectFromModel(GradientBoostingClassifier(random_state=0)) ), \n",
    "\n",
    "      (\"model\",  GradientBoostingClassifier(random_state=0) ), \n",
    "  ])\n",
    "  return pipeline_base\n",
    "\n",
    "  \n",
    "PipelineClf2ExplainClusters()\n",
    "\n",
    "We fit the classifier to the training data\n",
    "* Note again, here we are not doing a detailed hyperparameter optimization. This classification pipeline is useful only to the the features that look to be more important to predict the Clusters. We are not deploying this model, so fitting with default hyperparameter is typiically fine for this task\n",
    "\n",
    "pipeline_clf_cluster = PipelineClf2ExplainClusters()\n",
    "pipeline_clf_cluster.fit(X_train, y_train)\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Evaluate classifier performance on Train and Test Sets\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Tips.png\n",
    "\">\n",
    " In theory, we expect to have a good performance, since the Clusters were generated by the KMeans() and that algorithm has a logic. As a result, the classifier algorithm (GradientBoosting) would be able to map these relationships, in theory. So let's check that.\n",
    "\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Then evaluate the performance on the Train set using `classification_report()`\n",
    "* It looks that learned the relationships to ace all predictions in the train set\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, pipeline_clf_cluster.predict(X_train)))\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> And finally we evaluate in the test set\n",
    "* It looks that learned the relationship between the target and the features so it could generalize in the test set, since the performance is not distant from the train set.\n",
    "\n",
    "print(classification_report(y_test, pipeline_clf_cluster.predict(X_test)))\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Assess Most Important Features that define a cluster\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Now we assess the feature importance from the pipeline. First we need to know how many data cleaning and feature engineering your pipeline has\n",
    "* It is 1 step only: median imputation\n",
    "\n",
    "pipeline_clf_cluster\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We use the same code we saw in previous unit notebook where we grab the feature importance from feature selection step and store in a DataFrame\n",
    "* The plot shows that these are the 4 most important features in descending order: `['mean concavity', 'worst perimeter', 'worst fractal dimension', 'mean perimeter'] `\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Tips.png\n",
    "\"> **We are considering these as the most important variable that define a Cluster. They will be used to understand the Cluster Profile**\n",
    "\n",
    "# after data cleaning and feat engineering, the feature space changes\n",
    "\n",
    "data_cleaning_feat_eng_steps = 1 # how many data cleaning and feature engineering does your pipeline have?\n",
    "columns_after_data_cleaning_feat_eng = (Pipeline(pipeline_clf_cluster.steps[:data_cleaning_feat_eng_steps])\n",
    "                                        .transform(X_train)\n",
    "                                        .columns)\n",
    "\n",
    "best_features = columns_after_data_cleaning_feat_eng[pipeline_clf_cluster['feat_selection'].get_support()].to_list()\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "          'Feature': columns_after_data_cleaning_feat_eng[pipeline_clf_cluster['feat_selection'].get_support()],\n",
    "          'Importance': pipeline_clf_cluster['model'].feature_importances_})\n",
    "  .sort_values(by='Importance', ascending=False)\n",
    "  )\n",
    "\n",
    "best_features = df_feature_importance['Feature'].to_list() # reassign best features in importance order\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{best_features} \\n\")\n",
    "df_feature_importance.plot(kind='bar',x='Feature',y='Importance')\n",
    "plt.show()\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Cluster Analysis\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%209-%20Well%20done.png\"> Bravo! You know which variables to consider now to explain each cluster!\n",
    "* Let's create a custom function where we will explain the cluster profile, in terms of  `['mean concavity', 'worst perimeter', 'worst fractal dimension', 'mean perimeter']`. For each cluster, we want to know the most common values for each variable.\n",
    "\n",
    "* Go through the code and check the pseudo code to understand its logic. It may take a while to understand it, but the focus is to understand and apply the function to our business problem\n",
    "\n",
    "# df contains the most important features and the clusters\n",
    "# Note: your DataFrame needs to have a variable called 'Clusters' which will\n",
    "# contain the cluster prediction from the pipeline\n",
    "\n",
    "# It outputs a table showing for each cluster what is the most common values for a given variable\n",
    "\n",
    "def DescriptionAllClusters(df, decimal_points=3):\n",
    "\n",
    "  DescriptionAllClusters = pd.DataFrame(columns=df.drop(['Clusters'],axis=1).columns)\n",
    "  # iterate on each cluster , calls Clusters_IndividualDescription()\n",
    "  for cluster in df.sort_values(by='Clusters')['Clusters'].unique():\n",
    "    \n",
    "      EDA_ClusterSubset = df.query(f\"Clusters == {cluster}\").drop(['Clusters'],axis=1)\n",
    "      ClusterDescription = Clusters_IndividualDescription(EDA_ClusterSubset,cluster,decimal_points)\n",
    "      DescriptionAllClusters = DescriptionAllClusters.append(ClusterDescription)\n",
    "\n",
    "  \n",
    "  DescriptionAllClusters.set_index(['Cluster'],inplace=True)\n",
    "  return DescriptionAllClusters\n",
    "\n",
    "\n",
    "def Clusters_IndividualDescription(EDA_Cluster,cluster, decimal_points):\n",
    "\n",
    "  ClustersDescription = pd.DataFrame(columns=EDA_Cluster.columns)\n",
    "  # for a given cluster, iterate in all columns\n",
    "  # if the variable is numerical, calculate the IQR: display as Q1 -- Q3.\n",
    "    # That will show the range for the most common values for the numerical variable\n",
    "  # if the variable is categorical, count the frequencies and displays the top 3 most frequent\n",
    "    # That will show the most common levels for the category\n",
    "\n",
    "  for col in EDA_Cluster.columns:\n",
    "    \n",
    "    try:  # eventually a given cluster will have only mssing data for a given variable\n",
    "      \n",
    "      if EDA_Cluster[col].dtypes == 'object':\n",
    "        \n",
    "        top_frequencies = EDA_Cluster.dropna(subset=[col])[[col]].value_counts(normalize=True).nlargest(n=3)\n",
    "        Description = ''\n",
    "        \n",
    "        for x in range(len(top_frequencies)):\n",
    "          freq = top_frequencies.iloc[x]\n",
    "          category = top_frequencies.index[x][0]\n",
    "          CategoryPercentage = int(round(freq*100,0))\n",
    "          statement =  f\"'{category}': {CategoryPercentage}% , \"  \n",
    "          Description = Description + statement\n",
    "        \n",
    "        ClustersDescription.at[0,col] = Description[:-2]\n",
    "\n",
    "\n",
    "      \n",
    "      elif EDA_Cluster[col].dtypes in ['float', 'int']:\n",
    "        DescStats = EDA_Cluster.dropna(subset=[col])[[col]].describe()\n",
    "        Q1 = round(DescStats.iloc[4,0], decimal_points)\n",
    "        Q3 = round(DescStats.iloc[6,0], decimal_points)\n",
    "        Description = f\"{Q1} -- {Q3}\"\n",
    "        ClustersDescription.at[0,col] = Description\n",
    "    \n",
    "    \n",
    "    except Exception as e:\n",
    "      ClustersDescription.at[0,col] = 'Not available'\n",
    "      print(f\"** Error Exception: {e} - cluster {cluster}, variable {col}\")\n",
    "  \n",
    "  ClustersDescription['Cluster'] = str(cluster)\n",
    "  \n",
    "  return ClustersDescription\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> The next custom function is called `cluster_distribution_per_variable() ` and is used to analyze the Clusters and given Variable - in our case it will evaluate **Clusters x Diagnostic**.\n",
    "* It will show the absolute and relative levels of Diagnostic (Malignant and Benign) per cluster\n",
    "* Go through the code and check the pseudo code to understand its logic. It may take a while to understand it, but the focus is to understand and apply the function to our business problem\n",
    "\n",
    "import plotly.express as px\n",
    "def cluster_distribution_per_variable(df,target):\n",
    "\n",
    "  # the data should have 2 variables, the cluster predictions and\n",
    "  # the variable you want to analyze with, in this case we call \"target\"\n",
    "  \n",
    "  # we use plotly express to create 2 plots\n",
    "  # cluster distribution across the target\n",
    "  # relative presence of the target level in each cluster\n",
    "  \n",
    "   \n",
    "  df_bar_plot = df.value_counts([\"Clusters\", target]).reset_index() \n",
    "  df_bar_plot.columns = ['Clusters',target,'Count']\n",
    "  df_bar_plot[target] = df_bar_plot[target].astype('object')\n",
    "\n",
    "  print(f\"Clusters distribution across {target} levels\")\n",
    "  fig = px.bar(df_bar_plot, x='Clusters',y='Count',color=target,width=800, height=500)\n",
    "  fig.update_layout(xaxis=dict(tickmode= 'array',tickvals= df['Clusters'].unique()))\n",
    "  fig.show()\n",
    "\n",
    "\n",
    "  df_relative = (df\n",
    "                 .groupby([\"Clusters\", target])\n",
    "                 .size()\n",
    "                 .groupby(level=0)\n",
    "                 .apply(lambda x:  100*x / x.sum())\n",
    "                 .reset_index()\n",
    "                 .sort_values(by=['Clusters'])\n",
    "                 )\n",
    "  df_relative.columns = ['Clusters',target,'Relative Percentage (%)']\n",
    " \n",
    "\n",
    "  print(f\"Relative Percentage (%) of {target} in each cluster\")\n",
    "  fig = px.line(df_relative, x='Clusters',y='Relative Percentage (%)',color=target,width=800, height=500)\n",
    "  fig.update_layout(xaxis=dict(tickmode= 'array',tickvals= df['Clusters'].unique()))\n",
    "  fig.update_traces(mode='markers+lines')\n",
    "  fig.show()\n",
    " \n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> To start the analysis we want a DataFrame that contains best features and Clusters Predictions, since we want to analyze the patterns for each cluster\n",
    "* we will copy `df_clf` DataFrame (since it has all features and Cluster predictions) and filter `best_features` plus `['Clusters']`.\n",
    "\n",
    "\n",
    "df_cluster_profile = df_clf.copy()\n",
    "df_cluster_profile = df_cluster_profile.filter(items=best_features + ['Clusters'], axis=1)\n",
    "print(df_cluster_profile.shape)\n",
    "df_cluster_profile.head(3)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> We want also to analyze Diagnostic levels\n",
    "* In this exercise, we get it from `data.target` and create a DataFrame.\n",
    "* We know in advance Diagnostic represents a categorical variable and came as integer. Therefore we change its data type to `'object'`.\n",
    "\n",
    "df_diagnostic = pd.DataFrame(data.target, columns=['diagnostic'])\n",
    "df_diagnostic['diagnostic'] = df_diagnostic['diagnostic'].astype('object')\n",
    "df_diagnostic.head(3)\n",
    "\n",
    "---\n",
    "\n",
    "#### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Cluster profile on most important features\n",
    "\n",
    "We call `DescriptionAllClusters()` and parse a concatenated DataFrame made with `df_cluster_profile` and `df_diagnostic`. Before parsing let's just show this concatenated data, so you can get it clear.\n",
    "* It has the best features `['mean concavity', 'worst perimeter', 'worst fractal dimension', 'mean perimeter']`, Cluster Predictions and Diagnostic (where 0 is malignant, 1 is benign)\n",
    "\n",
    "\n",
    "\n",
    "pd.concat([df_cluster_profile,df_diagnostic], axis=1).head(4)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Finally, we use `DescriptionAllClusters()` parsing the concatenated DataFrame. It outputs a table shoing for each cluster what is the most common values for a given variable, including the diagnostic level (where 0 is malignant, 1 is benign). You will also parse the decimal points you want to see when the evaluated variable is numerical, depending on the range of the numerical variable you need more decimal points. In our case, 2 decimal points are fine, but you can re-run the function after and check with different values, like 0 and 4.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Result.png\n",
    "\"> Recall that we found the most important variables that help to define a cluster are: `['mean concavity', 'worst perimeter', 'worst fractal dimension', 'mean perimeter']`\n",
    "* Note that the algorithm found that for Cluster 0, the most common values for mean concavity is between 0.13 -- 0.22, for worst perimeter is 145.7 -- 174.18, worst fractal is between\t0.08 -- 0.09 and mean perimeter beteen\t120.88 -- 136.88. Also, all diagnostic in cluster 0 is 0 - malignant. **This is the profile from cluster 0!**\n",
    "  * Repeat this analysis for the remaining clusters. Note we start giving meaning for each cluster.\n",
    "* Note also our analyzed variable (diagnostic). It shows that cluster 0 has  only malignant cases, cluster 1 is a mix between malignant and bening but malignant is more dominant, and cluster has 2 only benign cases. \n",
    "  * Think for a moment how cool that is. The algorithm found patterns to split in 3 groups, 1 with malignant, another a mix and the last benign. Now think how this analysis could be applied to solve other business problems.\n",
    "\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> Note the major differences/patterns between clusters across variables, like:\n",
    "  * The ranges of mean concavity look to be smaller when diagnostic is benign (1) and look to increase when diganostic tends to be 0 (malignant) \n",
    "  * The values of worst perimeter in clusters where malignant is predominant, tend to be higher than in benign cluster.\n",
    "    * Note we keep adding meaning on how the clusters interact based on the analysis between a given variable (mean concavity for example) and diagnostic\n",
    "  * Repeat the same analysis for other variables (worst fractal and mean perimeter)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Tips.png\n",
    "\">\n",
    " Typically you will notice differences in ranges acrros the clusters and across the levels of your analyzed variable (diagnostic). This difference is typically the pattern we are interested to discover.\t\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "clusters_profile = DescriptionAllClusters(df=pd.concat([df_cluster_profile,df_diagnostic], axis=1),\n",
    "                                          decimal_points=2)\n",
    "clusters_profile\n",
    "\n",
    "---\n",
    "\n",
    "#### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> Clusters distribution across Diagnostic levels & Relative Percentage of Diagnostic in each cluster\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%207-%20Note.png\"> This analyzes shows now the Clusters distribution across Diagnostic. Actually, this information is revealed in the previous table, but now we can make more visual to stakeholders. It has 2 plots\n",
    "* The first is a bar plot, in the x axis the clusters, the bar length is how many data points in that cluster and is colored by the level of diagnosis (where 0 is malignant, 1 is benign)\n",
    "* The second plot gives a complementary vision to the first. In the first we saw the absolute values (the counts). Now we see the relative (the percentage)\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Result.png\n",
    "\"> Let's analyze the plots\n",
    "* The first plot shows that cluster 0 has malignant cases only, cluster 1 a mix of both cases with malignant predominance and the last cluster is predominantly benign cases (however there are few malignant cases. If that is required, you could do a data analysis later on this malignant cases.)\n",
    "* The second plot quicly reveals the percentage presence of Diagnostic (malignant and benign) in each cluster.\n",
    "\n",
    "\n",
    "df_cluster_vs_diagnostic=  df_diagnostic.copy()\n",
    "df_cluster_vs_diagnostic['Clusters'] = X['Clusters']\n",
    "cluster_distribution_per_variable(df=df_cluster_vs_diagnostic, target='diagnostic')\n",
    "\n",
    "---\n",
    "\n",
    "### <img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%2010-%20Lesson%20Content.png\"> What should I do now?\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\"https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Icon%209-%20Well%20done.png\"> You could deploy the Cluster Pipeline as it is, however it would **need all 30 variables** to predict a given cluster for a new breast sample. even though you used 4 variables to describe the profile from each cluster.\n",
    "* In real system, we should consider the amount of input variables we want to manage\n",
    "* Therefore we would consider an additional step for trying to **refit the cluster pipeline the most important variables**. We say \"trying\" since we will need to conduct a tradeoff analysis to validate if the pipeline with all variables and the pipeline with ony \"best feature\" produce \"equivalent\" results.\n",
    "  * In case they produce \"equivalent\" results, you can deploy a pipeline with less variables that will deliver similar performance.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img width=\"3%\" height=\"3%\" align=\"top\"  src=\" https://codeinstitute.s3.amazonaws.com/predictive_analytics/jupyter_notebook_icons/Tips.png\n",
    "\"> However, we will study this approach in our second walkthrough project\n",
    "* For the moment, what really matters is to understand that we can **cluster the data on similar datapoints, explain the profile of clusters, and we can analyze the clusters vs another variable** (in our case, clusters vs diagnostic)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
